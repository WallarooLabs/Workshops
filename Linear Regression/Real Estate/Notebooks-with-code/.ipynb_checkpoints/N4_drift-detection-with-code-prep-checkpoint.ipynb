{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Drift Detection Preparation\n",
    "\n",
    "This notebook is used to create inference data for the drift detection notebooks.  The plan is to run these an hour or a day before so the workshop participants can use them for their training.\n",
    "\n",
    "This notebook will have the bare minimum necessary for the training.  The rest will be part of the N4_drift_detection.ipynb notebook to actually demonstrate using assays for drift detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "* Load the workspace, pipeline, and model versions.\n",
    "* Perform sample inferences to:\n",
    "  * Set the baseline\n",
    "  * Perform \"normal\" inferences.\n",
    "  * Perform inferences that should trigger alerts.\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step will be to import our libraries, and set variables used through this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# used to display DataFrame information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "workspace_name = 'workshop-workspace-john-05'\n",
    "main_pipeline_name = 'houseprice-estimator'\n",
    "model_name_control = 'house-price-prime'\n",
    "\n",
    "# ignoring warnings for demonstration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# used to display DataFrame information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please log into the following URL in a web browser:\n",
      "\n",
      "\thttps://doc-test.keycloak.wallaroocommunity.ninja/auth/realms/master/device?user_code=VIVM-QUKD\n",
      "\n",
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Helper Functions\n",
    "\n",
    "The following helper functions are used to retrieve the workspace, pipelines, and models that were established in N1_deploy_a_model.ipynb.  Verify that the workspace, pipeline, and model names all match that notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Workspace, Pipeline, and Models\n",
    "\n",
    "Retrieve the workspace, pipeline and model from notebook N1_deploy_a_model.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'workshop-workspace-john-05', 'id': 10, 'archived': False, 'created_by': 'fa780cd9-154a-4456-848b-5934f703fcdb', 'created_at': '2024-03-11T17:58:57.996784+00:00', 'models': [{'name': 'house-price-prime', 'versions': 1, 'owner_id': '\"\"', 'last_update_time': datetime.datetime(2024, 3, 11, 17, 58, 59, 18588, tzinfo=tzutc()), 'created_at': datetime.datetime(2024, 3, 11, 17, 58, 59, 18588, tzinfo=tzutc())}], 'pipelines': [{'name': 'houseprice-estimator', 'create_time': datetime.datetime(2024, 3, 11, 17, 58, 59, 194422, tzinfo=tzutc()), 'definition': '[]'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "          <td>Name</td>\n",
       "          <td>house-price-prime</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Version</td>\n",
       "          <td>6082ad4c-e034-4bb1-a9e7-dc267b149adc</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>File Name</td>\n",
       "          <td>xgb_model.onnx</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>SHA</td>\n",
       "          <td>31e92d6ccb27b041a324a7ac22cf95d9d6cc3aa7e8263a229f7c4aec4938657c</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Status</td>\n",
       "          <td>ready</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Image Path</td>\n",
       "          <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Updated At</td>\n",
       "          <td>2024-11-Mar 17:58:59</td>\n",
       "        </tr>\n",
       "      </table>"
      ],
      "text/plain": [
       "{'name': 'house-price-prime', 'version': '6082ad4c-e034-4bb1-a9e7-dc267b149adc', 'file_name': 'xgb_model.onnx', 'image_path': None, 'last_update_time': datetime.datetime(2024, 3, 11, 17, 58, 59, 18588, tzinfo=tzutc())}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>houseprice-estimator</td></tr><tr><th>created</th> <td>2024-03-11 17:58:59.194422+00:00</td></tr><tr><th>last_updated</th> <td>2024-03-11 18:15:20.007804+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>e2c02684-b936-4eaa-ae22-16cc425ac1a7, 90680a22-b46c-4c4c-9c93-cecf87860321, d7ae395c-c5db-41aa-abfa-37aab4050924, e2c920d7-f993-4974-86ff-fdb5230ff590</td></tr><tr><th>steps</th> <td>house-price-prime</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'houseprice-estimator', 'create_time': datetime.datetime(2024, 3, 11, 17, 58, 59, 194422, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## blank space to log in \n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "# retrieve the previous workspace, model, and pipeline version\n",
    "\n",
    "workspace_name = \"workshop-workspace-john-05\"\n",
    "\n",
    "workspace = wl.get_workspace(name=workspace_name, create_if_not_exist=True)\n",
    "\n",
    "# set your current workspace to the workspace that you just created\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "# optionally, examine your current workspace\n",
    "wl.get_current_workspace()\n",
    "\n",
    "model_name = 'house-price-prime'\n",
    "\n",
    "prime_model_version = wl.get_model(model_name)\n",
    "\n",
    "pipeline_name = 'houseprice-estimator'\n",
    "\n",
    "pipeline = wl.get_pipeline(pipeline_name)\n",
    "\n",
    "display(workspace)\n",
    "display(prime_model_version)\n",
    "display(pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Pipeline\n",
    "\n",
    "Deploy the pipeline with the model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>houseprice-estimator</td></tr><tr><th>created</th> <td>2024-03-11 17:58:59.194422+00:00</td></tr><tr><th>last_updated</th> <td>2024-03-11 19:09:18.809008+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>77ad5fac-733b-40aa-8471-2b623731a1c2, e2c02684-b936-4eaa-ae22-16cc425ac1a7, 90680a22-b46c-4c4c-9c93-cecf87860321, d7ae395c-c5db-41aa-abfa-37aab4050924, e2c920d7-f993-4974-86ff-fdb5230ff590</td></tr><tr><th>steps</th> <td>house-price-prime</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'houseprice-estimator', 'create_time': datetime.datetime(2024, 3, 11, 17, 58, 59, 194422, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'house-price-prime', 'version': '6082ad4c-e034-4bb1-a9e7-dc267b149adc', 'sha': '31e92d6ccb27b041a324a7ac22cf95d9d6cc3aa7e8263a229f7c4aec4938657c'}]}}]\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.clear()\n",
    "pipeline.add_model_step(prime_model_version)\n",
    "\n",
    "deploy_config = wallaroo.DeploymentConfigBuilder().replica_count(1).cpus(0.5).memory(\"1Gi\").build()\n",
    "pipeline.deploy(deployment_config=deploy_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Sample Data\n",
    "\n",
    "Before creating the assays, we must generate data for the assays to build from.\n",
    "\n",
    "For this example, we will:\n",
    "\n",
    "* Perform sample inferences based on lower priced houses and use that as our baseline.\n",
    "* Generate inferences from specific set of high priced houses create inference outputs that will be outside the baseline.  This is used in later steps to demonstrate baseline comparison against assay analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference Results History Generation\n",
    "\n",
    "To start the demonstration, we'll create a baseline of values from houses with small estimated prices and set that as our baseline.\n",
    "\n",
    "We will save the beginning and end periods of our baseline data to the variables `assay_baseline_start` and `assay_baseline_end`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_houses_inputs = pd.read_json('../data/lowprice.df.json')\n",
    "baseline_size = 500\n",
    "\n",
    "# Where the baseline data will start\n",
    "assay_baseline_start = datetime.datetime.now()\n",
    "\n",
    "# These inputs will be random samples of small priced houses.  Around 30,000 is a good number\n",
    "small_houses = small_houses_inputs.sample(baseline_size, replace=True).reset_index(drop=True)\n",
    "\n",
    "# Wait 60 seconds to set this data apart from the rest\n",
    "time.sleep(60)\n",
    "small_results = pipeline.infer(small_houses)\n",
    "\n",
    "# Set the baseline end\n",
    "\n",
    "assay_baseline_end = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Numpy Baseline Values\n",
    "\n",
    "This process generates a numpy array of the inference results used as baseline data in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the numpy values\n",
    "\n",
    "# set the results to a non-array value\n",
    "small_results_baseline_df = small_results.copy()\n",
    "small_results_baseline_df['variable']=small_results['out.variable'].map(lambda x: x[0])\n",
    "small_results_baseline_df\n",
    "\n",
    "# set the numpy array\n",
    "small_results_baseline = small_results_baseline_df['variable'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assay Test Data\n",
    "\n",
    "The following will generate inference data for us to test against the assay baseline.  For this, we will add in house data that generate higher house prices than the baseline data we used earlier.\n",
    "\n",
    "This process should take 6 minutes to generate the historical data we'll later use in our assays.  We store the DateTime `assay_window_start` to determine where to start out assay analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a spread of house values\n",
    "\n",
    "# # Set the start for our assay window period.\n",
    "assay_window_start = datetime.datetime.now()\n",
    "\n",
    "time.sleep(65)\n",
    "inference_size = 1000\n",
    "\n",
    "# And a spread of large house values\n",
    "\n",
    "small_houses_inputs = pd.read_json('../data/lowprice.df.json', orient=\"records\")\n",
    "small_houses = small_houses_inputs.sample(inference_size, replace=True).reset_index(drop=True)\n",
    "\n",
    "pipeline.infer(small_houses)\n",
    "\n",
    "time.sleep(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a spread of large house values\n",
    "\n",
    "time.sleep(65)\n",
    "inference_size = 1000\n",
    "\n",
    "# And a spread of large house values\n",
    "\n",
    "big_houses_inputs = pd.read_json('../data/highprice.df.json', orient=\"records\")\n",
    "big_houses = big_houses_inputs.sample(inference_size, replace=True).reset_index(drop=True)\n",
    "\n",
    "pipeline.infer(big_houses)\n",
    "\n",
    "time.sleep(65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy Main Pipeline\n",
    "\n",
    "With the examples and tutorial complete, we will undeploy the main pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpipeline.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the Assay Values\n",
    "\n",
    "We will store the following into a location configuration file:\n",
    "\n",
    "* `small_results_baseline`:  Used to create the baseline from the numpy values from sample inferences.\n",
    "* `assay_baseline_start`: When to start the baseline from the inference history.\n",
    "* `assay_baseline_end`: When to end the baseline from the inference history.\n",
    "* `assay_window_start`: When to start the assay window period for assay samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this step if the file is already there\n",
    "\n",
    "import numpy\n",
    "\n",
    "numpy.save('./small_results_baseline.npy', small_results_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_numpy = numpy.load('./small_results_baseline.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 3, 11, 19, 14, 59, 997423)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./assay_baseline_start', 'w') as file:\n",
    "    file.write(assay_baseline_start.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\"))\n",
    "assay_baseline_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 3, 11, 19, 16, 0, 128604)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./assay_baseline_end', 'w') as file:\n",
    "    file.write(assay_baseline_end.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\"))\n",
    "assay_baseline_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 3, 11, 19, 16, 0, 149220)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./assay_window_start', 'w') as file:\n",
    "    file.write(assay_window_start.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\"))\n",
    "assay_window_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 3, 11, 19, 14, 59, 997423)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the assay baseline start datetime\n",
    "\n",
    "with open('./assay_baseline_start', 'r') as file:\n",
    "    assay_baseline_start_test = datetime.datetime.strptime(file.read(), \"%d-%b-%Y (%H:%M:%S.%f)\")\n",
    "assay_baseline_start_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 3, 11, 19, 16, 0, 128604)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the assay baseline end datetime\n",
    "\n",
    "with open('./assay_baseline_end', 'r') as file:\n",
    "    assay_baseline_end_test = datetime.datetime.strptime(file.read(), \"%d-%b-%Y (%H:%M:%S.%f)\")\n",
    "assay_baseline_end_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 3, 11, 19, 16, 0, 149220)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the assay window start datetime\n",
    "\n",
    "with open('./assay_window_start', 'r') as file:\n",
    "    assay_window_start_test = datetime.datetime.strptime(file.read(), \"%d-%b-%Y (%H:%M:%S.%f)\")\n",
    "assay_window_start_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
