{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statsmodel Forecast Workshop Notebook 1: Deploy a Model\n",
    "\n",
    "For this workshop, let's pretend that you work for a bike rental company.  You have developed a model to predict the number of rentals for the week following a given date, based on data collected in the company's rental history database.\n",
    "\n",
    "In this set of exercises, you will build a model to predict house sale prices, and deploy it to Wallaroo.\n",
    "\n",
    "Before we start, let's load some libraries that we will need for this notebook (note that this may not be a complete list).\n",
    "\n",
    "* **IMPORTANT NOTE**:  This tutorial is geared towards a Wallaroo 2023.2.1 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preload needed libraries \n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# used to display DataFrame information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# used for unique connection names\n",
    "\n",
    "import string\n",
    "import random\n",
    "\n",
    "import pyarrow as pa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "#### Exercise: Build a model\n",
    "\n",
    "Use the house price data `seattle_housing.csv` in the `data` subdirectory to build a model to predict the sales price of homes based on the features in the data set. \n",
    "\n",
    "At the end of the exercise, you should have a notebook and possibly other artifacts to produce a model for predicting house prices. For the purposes of the exercise, please use a framework that can be converted to ONNX, such as scikit-learn or XGBoost.\n",
    "\n",
    "For assistance converting a model to ONNX, see the [Wallaroo Model Conversion Tutorials](https://docs.wallaroo.ai/wallaroo-tutorials/wallaroo-tutorials-conversion-tutorials/) for some examples.\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "If you prefer to shortcut this step, you can use one of the pre-trained model pickle files in the `models` subdirectory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blank space for training model, if needed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Ready to deploy\n",
    "\n",
    "Wallaroo natively supports models in the ONNX, Python based models, Tensorflow frameworks, and other frameworks via containerization. For this exercise, we assume that you have a model that can be converted to the ONNX framework. The first steps to deploying in Wallaroo, then, is to convert your model to ONNX, and to add some extra functions to your processing modules so Wallaroo can call them.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### Exercise: Convert your Model to ONNX\n",
    "\n",
    "Take the model that you created in the previous exercises, and convert it to ONNX supported by Wallaroo. If you need help, see the [Wallaroo ONNX conversion tips](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-upload-onnx/#onnx-conversion-tips).  The model can also be deployed to Wallaroo if is supported by Wallaroo.  See the [Wallaroo SDK Essentials Guide: Model Uploads and Registrations](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/)\n",
    "\n",
    "At the end of this exercise, you should have your model as a standalone artifact, for example, a file called `model.onnx`.\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "If you prefer to shortcut this exercise, you can use one of the Python models in the `models` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank space to load for converting model, if needed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ready to work with Wallaroo\n",
    "\n",
    "Now that you have a model ready to go, you can log into Wallaroo and set up a **workspace** to organize your deployment artifacts. A Wallaroo workspace is place to organize the deployment artifacts for a project, and to collaborate with other team members. For more information, see [the Wallaroo 101](https://docs.wallaroo.ai/wallaroo-101/). \n",
    "\n",
    "\n",
    "Logging into Wallaroo via the cluster's integrated JupyterLab is quite straightfoward:\n",
    "\n",
    "```python\n",
    "# Login through local Wallaroo instance \n",
    "wl = wallaroo.Client()\n",
    "```\n",
    "See [the documentation](https://docs.wallaroo.ai/wallaroo-101/#connect-to-the-wallaroo-instance) if you are logging into Wallaroo some other way.\n",
    "\n",
    "Once you are logged in, you can create a workspace and set it as your working environment. To make the first exercise easier, here is a convenience function to get or create a workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the workspace called <name>, or create it if it does not exist.\n",
    "# this function assumes your connection to wallaroo is called wl\n",
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then logging in and creating a workspace looks something like this:\n",
    "\n",
    "```python\n",
    "# Login through local Wallaroo instance \n",
    "wl = wallaroo.Client()\n",
    "```\n",
    "\n",
    "Setting up the workspace may resemble this.  Verify that the workspace name is unique across the Wallaroo instance.\n",
    "\n",
    "```python\n",
    "# workspace names need to be globally unique, so add a random suffix to insure this\n",
    "# especially important if the \"main\" workspace name is potentially a common one\n",
    "\n",
    "suffix= ''.join(random.choice(string.ascii_lowercase) for i in range(4))\n",
    "workspace_name = \"my-workspace\"+suffix\n",
    "\n",
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "# set your current workspace to the workspace that you just created\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "# optionally, examine your current workspace\n",
    "wl.get_current_workspace()\n",
    "\n",
    "```\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### Exercise: Log in and create a workspace\n",
    "\n",
    "Log into wallaroo, and create a workspace for this workshop. Then set that new workspace to your current workspace.\n",
    "Make sure you remember the name that you gave the workspace, as you will need it for later notebooks. Set that workspace to be your working environment.\n",
    "\n",
    "**Notes**\n",
    "* Workspace names must be globally unique, so don't pick something too common. The \"random suffix\" trick in the code snippet is one way to try to generate a unique workspace name, if you suspect you are using a common name. \n",
    "\n",
    "At the end of the exercise, you should be in a new workspace to do further work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blank spot to log in\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blank spot to connect to the workspace\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Simple Single-Step Pipeline\n",
    "\n",
    "Once your model is in the ONNX format, and you have a workspace to work in, you can easily upload your model to Wallaroo's production platform with just a few lines of code. For example, if you have a model called `model.onnx`, and you wish to upload it to Wallaroo with the name `mymodel`, then upload the model as follows (once you are in the appropriate workspace):\n",
    "\n",
    "```python\n",
    "\n",
    "my_model = wl.upload_model(\"mymodel\", \"model.onnx\", framework=Framework.ONNX).configure()\n",
    "```\n",
    "\n",
    "See [Wallaroo SDK Essentials Guide: Model Uploads and Registrations: ONNX](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-upload-onnx/) for full details.\n",
    "\n",
    "The function `upload_model()` returns a handle to the uploaded model that you will continue to work with in the SDK.\n",
    "\n",
    "### Upload Python Models\n",
    "\n",
    "If you choose to use one of our sample models, our forecast example uses a Python library ARIMA statsmodel.  The models are all available in the `./models` directory.\n",
    "\n",
    "To upload a Python model to Wallaroo, the following is required:\n",
    "\n",
    "* The name of the model:  What to designate the model name once uploaded to Wallaroo.\n",
    "* Path of the Python script:  This specifies the file location.  For example: `./models/my-python-script.py`\n",
    "* The input and output schemas:  These inform Wallaroo how inference request data will be formatted, and the shape of the data going out from the model.  The schema is in Apache Arrow schema format, aka `pyarrow.lib.Schema`..  These are required to be in the For example, if the inference inputs are a pandas DataFrame with the following shape:\n",
    "\n",
    "| &nbsp; | tensor |\n",
    "|---|---|\n",
    "| 0 | [15.5, 17.2, 35.724, 0.37894 ]\n",
    "\n",
    "With the following output:\n",
    "\n",
    "[\n",
    "    \"forecast\": [235, 135, 175],\n",
    "    \"average_forecast\": [181.66]\n",
    "]\n",
    "\n",
    "In this case, the input schema is represented as:\n",
    "\n",
    "```python\n",
    "import pyarrow as pa\n",
    "\n",
    "input_schema = pa.schema([\n",
    "    pa.field('tensor', pa.list_(pa.float64()))\n",
    "])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('forecast', pa.list_(pa.int64())),\n",
    "    pa.field('average_forecast', pa.list_(pa.float64()))\n",
    "])\n",
    "```\n",
    "\n",
    "Python models are uploaded to Wallaroo with the `upload_model` method, with the additional `configure` method specifying the `python` framework with the inputs and outputs.  For example:\n",
    "\n",
    "```python\n",
    "sample_model = (wl.upload_model(control_model_name, \n",
    "                                 control_model_file, \n",
    "                                 framework=Framework.PYTHON)\n",
    "                                 .configure(\"python\", \n",
    "                                 input_schema=input_schema, \n",
    "                                 output_schema=output_schema)\n",
    "                )\n",
    "```\n",
    "\n",
    "For more information about Python models, see [Wallaroo SDK Essentials Guide: Model Uploads and Registrations: Python Models](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-upload-python/).\n",
    "\n",
    "Once the model has been uploaded, you can create a **pipeline** that contains the model. The pipeline is the mechanism that manages deployments. A pipeline contains a series of **steps** - sequential sets of models which take in the data from the preceding step, process it through the model, then return a result. Some pipelines can have just one step, while others may have multiple models with multiple steps or arranged for A/B testing. Deployed pipelines allocate resources and can then process data either through local files or through a **deployment URL**.\n",
    "\n",
    "So for your model to accept inferences, you must add it to a pipeline. You can create a single step pipeline called `mypipeline` as follows.\n",
    "\n",
    "```python\n",
    "# create the pipeline\n",
    "my_pipeline = wl.build_pipeline(\"mypipeline\").add_model_step(my_model)\n",
    "\n",
    "# deploy the pipeline\n",
    "my_pipeline = my_pipeline.deploy()\n",
    "```\n",
    "\n",
    "Deploying the pipeline means that resources from the cluster are allocated to the pipeline, and it is ready to accept inferences. You can \"turn off\" the pipeline with the call `pipeline.undeploy()`, which returns the resources back to the cluster.  This is an important step - leaving pipeline deployed when they're no longer needed takes up resources that may be needed by other pipelines or services.\n",
    "\n",
    "See [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/) for full details.\n",
    "\n",
    "**More Hints**\n",
    "\n",
    "* `workspace = wl.get_current_workspace()` gives you a handle to the current workspace\n",
    "* then `workspace.models()` will return a list of the models in the workspace\n",
    "* and `workspace.pipelines()` will return a list of the pipelines in the workspace\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### Exercise: Upload and deploy your model\n",
    "\n",
    "Upload and deploy the ONNX model that you created in the previous exercise. For simplicity, do any needed pre-processing in the notebook.\n",
    "\n",
    "At the end of the exercise, you should have a model and a deployed pipeline in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank space to upload model, and create the pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Data to your Pipeline\n",
    "\n",
    "ONNX models generally expect their input as an array in a dictionary, keyed by input name. In Wallaroo, the default input name is \"tensor\". So (outside of Wallaroo), an ONNX model that expected three numeric values as its input would expect input data similar to the below: (**Note: The below examples are only notional, they aren't intended to work with our example models.**)\n",
    "\n",
    "```python\n",
    "# one datum\n",
    "singleton = {'tensor': [[1, 2, 3]] }\n",
    "\n",
    "# two datums\n",
    "two_inputs = {'tensor': [[1, 2, 3], [4, 5, 6]] }\n",
    "```\n",
    "\n",
    "In the Wallaroo SDK, you can send a pandas DataFrame representation of this dictionary (pandas record format) to the pipeline, via the `pipeline.infer()` method.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# one datum (notional example)\n",
    "sdf = pd.DataFrame(singleton)\n",
    "sdf\n",
    "#       tensor\n",
    "# 0  [1, 2, 3]\n",
    "\n",
    "# send the datum to a pipeline for inference\n",
    "# notional example - not houseprice model!\n",
    "result = my_pipeline.infer(sdf)\n",
    "\n",
    "# two datums\n",
    "# Note that the value of 'tensor' must be a list, not a numpy array \n",
    "twodf = pd.DataFrame(two_inputs)\n",
    "twodf\n",
    "#      tensor\n",
    "# 0  [1, 2, 3]\n",
    "# 1  [4, 5, 6]\n",
    "\n",
    "# send the data to a pipeline for inference\n",
    "# notional example, not houseprice model!\n",
    "result = my_pipeline.infer(twodf)\n",
    "```\n",
    "\n",
    "To send data to a pipeline via the inference URL (for example, via CURL), you need the JSON representation of these data frames.\n",
    "\n",
    "```python\n",
    "#\n",
    "# notional examples, not houseprice model!\n",
    "#\n",
    "sdf.to_json(orient='records')\n",
    "# '[{\"tensor\":[1,2,3]}]'\n",
    "\n",
    "twodf.to_json(orient='records')\n",
    "# '[{\"tensor\":[1,2,3]},{\"tensor\":[4,5,6]}]'\n",
    "```\n",
    "\n",
    "If the JSON data is in a file, you can send it to the pipeline from within the SDK via the `pipeline.infer_from_file()` method. \n",
    "\n",
    "In either case, a successful inference will return a data frame of inference results. The model inference(s) will be in the `column out.<outputname>`.\n",
    "\n",
    "For more details, see [Wallaroo SDK Essentials Guide: Inference Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-inferences/).\n",
    "\n",
    "### Inference Input with Forecast Statsmodel\n",
    "\n",
    "For our particular statsmodel, the input is stored in the file `day.csv`, which tracks bike rentals and conditions from 2011 through 2012.  The sample Python ARIMA Statsmodel used in these demonstrations has the following input and output schemas.\n",
    "\n",
    "```python\n",
    "input_schema = pa.schema([\n",
    "    pa.field('count', pa.list_(pa.int64()))\n",
    "])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('forecast', pa.list_(pa.int64())),\n",
    "    pa.field('weekly_average', pa.list_(pa.float64()))\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting from tabular format\n",
    "\n",
    "If your input data is in a standard tabular format (like the `test_data.csv` example data in the `data` directory), then you need to convert to pandas record format to send the data to your pipeline.  See the pandas DataFrame documentation for methods on how to import a CSV file to a DataFrame.\n",
    "\n",
    "To help with the following exercises, here are some convenience functions you might find useful for doing this conversion. These functions convert input data in standard tabular format (in a pandas DataFrame) to the pandas record format that the model expects.\n",
    "\n",
    "`get_singleton` assumes that all of the information is on a single row.\n",
    "\n",
    "`get_singleton_forecast` assumes that the data is composed in a single DataFrame, and then reformats it to be in a single row.  Our example ARIMA forecast model expects data in the input schema detailed above.  So a series of inputs such as:\n",
    "\n",
    "| &nbsp; | count |\n",
    "|---|---|\n",
    "| 0 | 985 |\n",
    "| 1 | 801 |\n",
    "| 2 |1349 |\n",
    "| 3 |1562 |\n",
    "| 4 |1600 |\n",
    "| 5 |1606 |\n",
    "| 6 |1510 |\n",
    "| 7 |959 |\n",
    "| 8 |822 |\n",
    "| 9 |1321 |\n",
    "\n",
    "Would have to be reformatted as:\n",
    "\n",
    "| &nbsp; | count |\n",
    "|---|---|\n",
    "| 0 | [985, 801, 1349, 1562, 1600, 1606, 1510, 959, 822, 1321] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull a single datum from a data frame \n",
    "# and convert it to the format the model expects\n",
    "def get_singleton(df, i):\n",
    "    singleton = df.iloc[i,:].to_numpy().tolist()\n",
    "    sdict = {'tensor': [singleton]}\n",
    "    return pd.DataFrame.from_dict(sdict)\n",
    "\n",
    "def get_singleton_forecast(df, field):\n",
    "    singleton = pd.DataFrame({field: [df[field].values.tolist()]})\n",
    "    return singleton\n",
    "\n",
    "# pull a batch of data from a data frame\n",
    "# and convert to the format the model expects\n",
    "def get_batch(df, first=0, nrows=1):\n",
    "    last = first + nrows\n",
    "    batch = df.iloc[first:last, :].to_numpy().tolist()\n",
    "    return pd.DataFrame.from_dict({'tensor': batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute the following code block to see examples of what `get_singleton` and `get_batch` do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ME!\n",
    "\n",
    "print('''TOY data for a model that takes inputs var1, var2, var3.\n",
    "The dataframe is called df.\n",
    "Pretend the model is in a Wallaroo pipeline called \"toypipeline\"''')\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'var1': [1, 3, 5],\n",
    "    'var2': [33, 88, 45],\n",
    "    'var3': [6, 20, 5]\n",
    "})\n",
    "\n",
    "display(df)\n",
    "\n",
    "# create a model input from the first row\n",
    "# this is now in the format that a model would accept\n",
    "singleton = get_singleton(df, 0)\n",
    "\n",
    "print('''The command \"singleton = get_singleton(df, 0)\" converts\n",
    "the first row of the data frame into the format that Wallaroo pipelines accept.\n",
    "You could now get a prediction by: \"toypipeline.infer(singleton)\".\n",
    "''')\n",
    "display(singleton)\n",
    "\n",
    "\n",
    "# create a batch of queries from the entire dataframe\n",
    "batch = get_batch(df, nrows=2)\n",
    "\n",
    "print('''The command \"batch = get_batch(df, nrows=2)\" converts\n",
    "the the first two rows of the data frame into a batch format that Wallaroo pipelines accept.\n",
    "You could now get a batch prediction by: \"toypipeline.infer(batch)\".\n",
    "''')\n",
    "display(batch)\n",
    "\n",
    "print('''The command \"singleton = get_singleton(df, 0)\" converts\n",
    "the first row of the data frame into the format that Wallaroo pipelines accept.\n",
    "You could now get a prediction by: \"toypipeline.infer(singleton)\".\n",
    "''')\n",
    "\n",
    "sample_df = pd.DataFrame({\"count\": [1526, \n",
    "                                    1550, \n",
    "                                    1708, \n",
    "                                    1005, \n",
    "                                    1623]\n",
    "                        })\n",
    "display(sample_df)\n",
    "\n",
    "inference_df = get_singleton_forecast(sample_df, 'count')\n",
    "display(inference_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "#### Exercise: Send data to your pipeline for inference.\n",
    "\n",
    "Create some test data from the housing data and send it to the pipeline that you deployed in the previous exercise.  \n",
    "\n",
    "* If you used the pre-provided models, then you can use `test_data.csv` from the `data` directory.  This can be loaded directly into **your** sample pandas DataFrame - check the pandas documentation for a handy function for doing that.  (We mention yours because sometimes people try to use the example code above rather than their own data.)\n",
    "\n",
    "* Start easy, with just one datum; retrieve the inference results. You can try small batches, as well. Use the above example as a guide.\n",
    "* Examine the inference results; observe what the model prediction column is called; it should be of the form `out.<outputname>`.\n",
    "\n",
    "For more hints about the different ways of sending data to the pipeline, and to see an example of the inference result format, see the [\"Running Inferences\" section of Wallaroo 101](https://docs.wallaroo.ai/wallaroo-101/#running-interfences).\n",
    "\n",
    "At the end of the exercise, you should have a set of inference results that you got through the Wallaroo pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  blank space to create test data, and send some data to your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Inferences through API\n",
    "\n",
    "For Wallaroo instances that enable external endpoints connections to pipelines, each pipeline has it's own URL that can be used to perform inferences through an API call.\n",
    "\n",
    "Performing an inference through an API requires the following:\n",
    "\n",
    "* The authentication token to authorize the connection to the pipeline.\n",
    "* The pipeline's inference URL.\n",
    "* Inference data to sent to the pipeline - in JSON, DataFrame records format, or Apache Arrow.\n",
    "\n",
    "Full details are available through the [Wallaroo API Connection Guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-api-guide/wallaroo-mlops-connection-guide/) on how retrieve an authorization token and perform inferences through the pipeline's API.\n",
    "\n",
    "For this demonstration, we'll use some Wallaroo methods to retrieve those items.\n",
    "\n",
    "First we'll request the pipeline url with the `_deployment._url()` method.\n",
    "\n",
    "* **IMPORTANT NOTE**:  The `_deployment._url()` method will return an **internal** URL when using Python commands from within the Wallaroo instance - for example, the Wallaroo JupyterHub service.  When connecting via an external connection, `_deployment._url()` returns an **external** URL.\n",
    "  * External URL connections requires [the authentication be included in the HTTP request](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-api-guide/), and [Model Endpoints](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-model-endpoints-guide/) are enabled in the Wallaroo configuration options.\n",
    "\n",
    "For example, to retrieve the inference URL we will request it from a sample pipeline like so:\n",
    "\n",
    "```python\n",
    "inference_url = my_pipeline._deployment._url()\n",
    "```\n",
    "\n",
    "For the authentication headers, we can use the Wallaroo client method `wl.auth.auth_header()`.  This returns a header with the bearer token needed to authenticate.  Then we set what data we're sending over as the `Content-Type` and the `Accept` for what we expect to receive back.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "```python\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "headers['Content-Type']='application/json; format=pandas-records'\n",
    "headers['Accept']='application/json; format=pandas-records'\n",
    "```\n",
    "\n",
    "Here's the Content-Types and Accepts depending on the data types:\n",
    "\n",
    "* Pandas DataFrame: `'application/json; format=pandas-records'`\n",
    "* Apache Arrow Table: `'application/vnd.apache.arrow.file'`\n",
    "* JSON: `'application/json'`\n",
    "\n",
    "Last is how we're going to connect.  We'll use for our example here the Python `requests` library which can create a POST connection to our pipeline, submit the authentication and content type headers, then submit the information.\n",
    "\n",
    "For Pandas DataFrame, this can be converted to JSON pandas record with the following:\n",
    "\n",
    "```python\n",
    "df.to_json(orient=\"records\")\n",
    "```\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "deploy_url = pipeline._deployment._url()\n",
    "display(deploy_url)\n",
    "\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "headers['Content-Type']='application/json; format=pandas-records'\n",
    "headers['Accept']='application/json; format=pandas-records'\n",
    "\n",
    "# get our data\n",
    "multiple_batch = get_batch(df_from_csv, nrows=5)\n",
    "display(multiple_batch.to_json(orient=\"records\"))\n",
    "\n",
    "# submit the request via POST, import as pandas DataFrame\n",
    "response = requests.post(\n",
    "        deploy_url, \n",
    "        data=multiple_batch.to_json(orient=\"records\"), \n",
    "        headers=headers).json()\n",
    "\n",
    "display(response)\n",
    "```\n",
    "\n",
    "The response comes back as JSON ready to be converted to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### put your API request to the pipeline here.  For extra credit,\n",
    "### try it with requests, curl, etc.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undeploying Your Pipeline\n",
    "\n",
    "You should always undeploy your pipelines when you are done with them, or don't need them for a while. This releases the resources that the pipeline is using for other processes to use. You can always redeploy the pipeline when you need it again. As a reminder, here are the commands to deploy and undeploy a pipeline:\n",
    "\n",
    "```python\n",
    "\n",
    "# when the pipeline is deployed, it's ready to receive data and infer\n",
    "pipeline.deploy()\n",
    "\n",
    "# \"turn off\" the pipeline and releaase its resources\n",
    "pipeline.undeploy()\n",
    "\n",
    "```\n",
    "\n",
    "If you are continuing on to the next notebook now, you can leave the pipeline deployed to keep working; but if you are taking a break, then you should undeploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank space to undeploy the pipeline, if needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You have now \n",
    "\n",
    "* Successfully trained a model\n",
    "* Converted your model and uploaded it to Wallaroo\n",
    "* Created and deployed a simple single-step pipeline\n",
    "* Successfully send data to your pipeline for inference\n",
    "\n",
    "In the next notebook, you will look at two different ways to evaluate your model against the real world environment.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
