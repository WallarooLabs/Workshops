{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodel Forecast with Wallaroo Features: Deploy and Test Infer\n",
    "\n",
    "This tutorial series demonstrates how to use Wallaroo to deploy a statsmodel ARIMA forecast model and perform sample inferences through it.\n",
    "\n",
    "In the previous step \"Statsmodel Forecast with Wallaroo Features: Model Creation\", the statsmodel was trained and saved to the Python file `forecast.py`.  This file will now be uploaded to a Wallaroo instance as a Python model, then used for sample inferences.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* A Wallaroo instance version 2023.2.1 or greater.\n",
    "\n",
    "## References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Model Uploads and Registrations: Python Models](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-upload-python/)\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)\n",
    "* [Wallaroo SDK Essentials: Inference Guide: Parallel Inferences](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-inferences/#parallel-inferences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Steps\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step is to import the libraries that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.2.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wallaroo.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please log into the following URL in a web browser:\n",
      "\n",
      "\thttps://doc-test.keycloak.wallaroocommunity.ninja/auth/realms/master/device?user_code=DQYP-YCIW\n",
      "\n",
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "wallarooPrefix = \"doc-test.\"\n",
    "wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "# wallarooPrefix = \"product-uat-ee.\"\n",
    "# wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configurations\n",
    "\n",
    "The following will set the workspace, model name, and pipeline that will be used for this example.  If the workspace or pipeline already exist, then they will assigned for use in this example.  If they do not exist, they will be created based on the names listed below.\n",
    "\n",
    "Workspace names must be unique.  To allow this tutorial to run in the same Wallaroo instance for multiple users, set the `suffix` variable or share the workspace with other users.\n",
    "\n",
    "#### Set Configurations References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Workspace Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-workspace/)\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for unique connection names\n",
    "\n",
    "# import string\n",
    "# import random\n",
    "\n",
    "# suffix= ''.join(random.choice(string.ascii_lowercase) for i in range(4))\n",
    "\n",
    "suffix='jchnew'\n",
    "\n",
    "workspace_name = f'forecast-model-workshop{suffix}'\n",
    "\n",
    "pipeline_name = 'forecast-workshop-pipeline'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Workspace and Pipeline\n",
    "\n",
    "The workspace will be either used or created if it does not exist, along with the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline\n",
    "\n",
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Model\n",
    "\n",
    "The Python model created in \"Forecast and Parallel Infer with Statsmodel: Model Creation\" will now be uploaded.  Note that the Framework is set to `Framework.PYTHON` to inform the Wallaroo engine on what model framework is being added.\n",
    "\n",
    "The other versions of the model are also uploaded in this step to show how to hot swap between models and other uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload three models:  the control and two challengers\n",
    "\n",
    "control_model_name = 'forecast-control-model'\n",
    "control_model_file = './forecast_standard.py'\n",
    "\n",
    "challenger01_model_name = 'forecast-challenger01-model'\n",
    "challenger01_model_file = './forecast_alternate01.py'\n",
    "\n",
    "challenger02_model_name = 'forecast-challenger02-model'\n",
    "challenger02_model_file = './forecast_alternate02.py'\n",
    "\n",
    "# Holding on these for later\n",
    "# input_schema = pa.schema([\n",
    "#     pa.field('count', pa.list_(pa.int64(), list_size=7))\n",
    "# ])\n",
    "\n",
    "input_schema = pa.schema([\n",
    "    pa.field('count', pa.int64())\n",
    "])\n",
    "# output_schema = pa.schema([\n",
    "#     pa.field('forecast', pa.list_(pa.int64()))\n",
    "# ])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('forecast', pa.int64())\n",
    "])\n",
    "\n",
    "# upload the models\n",
    "\n",
    "bike_day_model = wl.upload_model(control_model_name, \n",
    "                                 control_model_file, \n",
    "                                 input_schema=input_schema,\n",
    "                                 output_schema=output_schema,\n",
    "                                 framework = Framework.PYTHON)\n",
    "\n",
    "bike_day_model = wl.upload_model(control_model_name, control_model_file, Framework.PYTHON)\n",
    "\n",
    "challenger_model_01 = wl.upload_model(challenger01_model_name, challenger01_model_file, Framework.PYTHON)\n",
    "\n",
    "challenger_model_02 = wl.upload_model(challenger02_model_name, challenger02_model_file, Framework.PYTHON)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Pipeline\n",
    "\n",
    "We will now add the uploaded model as a step for the pipeline, then deploy it.\n",
    "\n",
    "Until a pipeline is deployed, the steps assigned to it only exist in the local memory.  During deployment the pipeline steps, configurations, and other details are set in the database, and resources allocated from the cluster for the pipeline's use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>forecast-workshop-pipeline</td></tr><tr><th>created</th> <td>2023-07-28 15:14:53.116222+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-28 15:14:53.116222+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>5efbf5f1-74c7-46f0-9f66-9866f66ead89</td></tr><tr><th>steps</th> <td>forecast-control-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'forecast-workshop-pipeline', 'create_time': datetime.datetime(2023, 7, 28, 15, 14, 53, 116222, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'forecast-control-model', 'version': '8530bdf0-842a-4b75-8bb5-4f8b2999822a', 'sha': '19570de73a3cad49145e7d6c9f5ffce02628936b77fbb542c33f0c533d0b05a8'}]}}]\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the deployment to allow for additional engines to run\n",
    "# Undeploy and clear the pipeline in case it was used in other demonstrations\n",
    "pipeline.undeploy()\n",
    "pipeline.clear()\n",
    "deploy_config = (wallaroo.DeploymentConfigBuilder()\n",
    "                        .replica_count(1)\n",
    "                        .replica_autoscale_min_max(minimum=2, maximum=5)\n",
    "                        .cpus(0.25)\n",
    "                        .memory(\"512Mi\")\n",
    "                        .build()\n",
    "                    )\n",
    "\n",
    "pipeline.add_model_step(bike_day_model)\n",
    "\n",
    "pipeline.deploy(deployment_config = deploy_config)\n",
    "# pipeline.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ModelInference': {'models': [{'name': 'forecast-control-model', 'version': '8530bdf0-842a-4b75-8bb5-4f8b2999822a', 'sha': '19570de73a3cad49145e7d6c9f5ffce02628936b77fbb542c33f0c533d0b05a8'}]}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference\n",
    "\n",
    "Run a test inference to verify the pipeline is operational from the sample test data stored in `./data/testdata_dict.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1764, 1749, 1743, 1741, 1740, 1740, 1740]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inferencedata = json.load(open(\"./data/testdata_dict.json\"))\n",
    "\n",
    "results = pipeline.infer(inferencedata)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot Swap Model\n",
    "\n",
    "Models are \"hot swapped\" - aka the pipeline step for the model is replaced with another model - without undeploying the pipeline.  During the hot swap, a model in a pipeline step is \"swapped\" with another model.  Incoming inferences are cached during the milliseconds it takes to update the step with the new model, then submitted to the pipeline with the new step.\n",
    "\n",
    "To replace a pipeline step, use the Pipeline `replace_with_model_step(index, model)`, where `index` is the step number ordered from zero, and the `model` is the model to be replacing it with.  The pipeline is then deployed - even if currently already deployed - to store the updated settings and update the pipeline with resource allocation, etc.\n",
    "\n",
    "Once the model is swapped out, we will perform another sample inference to test the difference in output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ModelInference': {'models': [{'name': 'forecast-challenger01-model', 'version': '3b925f2b-929a-4972-9dbe-c4b2fde64da8', 'sha': '5e00b7106b4a07f85c14bcaaf62b05aa775448918f6446f4d834ab103dd1aa67'}]}}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1703, 1757, 1737, 1744, 1742, 1743, 1742]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline.replace_with_model_step(0, challenger_model_01)\n",
    "\n",
    "pipeline.deploy()\n",
    "\n",
    "inferencedata = json.load(open(\"./data/testdata_dict.json\"))\n",
    "\n",
    "display(pipeline.steps())\n",
    "\n",
    "results = pipeline.infer(inferencedata)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Logs\n",
    "\n",
    "Logs are displayed with the Pipeline `logs()` method.  This displays the log for the current version.  Adding the parameter `dataset=[\"time\", \"out.json\",\"metadata\"]` lets us get the metadata parameter `metadata.last_model` to show what model was used for the inference request.\n",
    "\n",
    "#### Pipeline Logs References\n",
    "\n",
    "[Wallaroo SDK Essentials Guide: Pipeline Log Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline-logs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out.json</th>\n",
       "      <th>metadata.last_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-28 15:15:40.413</td>\n",
       "      <td>{\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}</td>\n",
       "      <td>{\"model_name\":\"forecast-control-model\",\"model_sha\":\"19570de73a3cad49145e7d6c9f5ffce02628936b77fbb542c33f0c533d0b05a8\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-28 15:15:53.574</td>\n",
       "      <td>{\"forecast\":[1703,1757,1737,1744,1742,1743,1742]}</td>\n",
       "      <td>{\"model_name\":\"forecast-challenger01-model\",\"model_sha\":\"5e00b7106b4a07f85c14bcaaf62b05aa775448918f6446f4d834ab103dd1aa67\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time                                           out.json  \\\n",
       "0 2023-07-28 15:15:40.413  {\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}   \n",
       "1 2023-07-28 15:15:53.574  {\"forecast\":[1703,1757,1737,1744,1742,1743,1742]}   \n",
       "\n",
       "                                                                                                           metadata.last_model  \n",
       "0       {\"model_name\":\"forecast-control-model\",\"model_sha\":\"19570de73a3cad49145e7d6c9f5ffce02628936b77fbb542c33f0c533d0b05a8\"}  \n",
       "1  {\"model_name\":\"forecast-challenger01-model\",\"model_sha\":\"5e00b7106b4a07f85c14bcaaf62b05aa775448918f6446f4d834ab103dd1aa67\"}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pipeline.logs(dataset=[\"time\", \"out.json\",\"metadata\"]) \\\n",
    "        .loc[:, [\"time\", \"out.json\", \"metadata.last_model\"]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "Undeploy the pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>forecast-workshop-pipeline</td></tr><tr><th>created</th> <td>2023-07-28 15:14:53.116222+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-28 15:15:41.248933+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>e86d795d-71b0-4537-85a3-261806fc0c29, 5efbf5f1-74c7-46f0-9f66-9866f66ead89</td></tr><tr><th>steps</th> <td>forecast-control-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'forecast-workshop-pipeline', 'create_time': datetime.datetime(2023, 7, 28, 15, 14, 53, 116222, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'forecast-challenger01-model', 'version': '3b925f2b-929a-4972-9dbe-c4b2fde64da8', 'sha': '5e00b7106b4a07f85c14bcaaf62b05aa775448918f6446f4d834ab103dd1aa67'}]}}]\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
