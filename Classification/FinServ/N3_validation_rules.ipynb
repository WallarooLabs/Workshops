{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6540f10a-6e1c-44ba-b344-0a476491dce6",
   "metadata": {},
   "source": [
    "# Workshop Notebook 3: Observability Part 1 - Validation Rules\n",
    "\n",
    "In the previous notebooks you uploaded the models and artifacts, then deployed the models to production through provisioning workspaces and pipelines. Now you're ready to put your feet up! But to keep your models operational, your work's not done once the model is in production. You must continue to monitor the behavior and performance of the model to insure that the model provides value to the business.\n",
    "\n",
    "In this notebook, you will learn about adding validation rules to pipelines.\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "In the blocks below we will preload some required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d0f316-7000-467e-b5d2-1a1c4e18d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preload needed libraries \n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# used to display DataFrame information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# used for unique connection names\n",
    "\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef118f2",
   "metadata": {},
   "source": [
    "## Login to Wallaroo\n",
    "\n",
    "Retrieve the previous workspace, model versions, and pipelines used in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ca3872-038b-4851-bee2-069799ac0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank space to log in \n",
    "\n",
    "\n",
    "\n",
    "# retrieve the previous workspace, model, and pipeline version\n",
    "\n",
    "\n",
    "\n",
    "# set your current workspace to the workspace that you just created\n",
    "\n",
    "\n",
    "# optionally, examine your current workspace\n",
    "\n",
    "# get the model version and pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54328276",
   "metadata": {},
   "source": [
    "## Deploy the Pipeline\n",
    "\n",
    "Add the model version as a pipeline step to our pipeline, and deploy the pipeline.  You may want to check the pipeline steps to verify that the right model version is set for the pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b7fb3b-4e56-4ba8-bb39-82ac75512534",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank space to get your pipeline and run a small batch of data through it to see the range of predictions\n",
    "\n",
    "\n",
    "\n",
    "deploy_config = wallaroo.DeploymentConfigBuilder().replica_count(1).cpus(0.5).memory(\"1Gi\").build()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e418910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferences here\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55ffbcff-cd3c-48b7-9cd5-88119b482f40",
   "metadata": {},
   "source": [
    "## Model Validation Rules\n",
    "\n",
    "A simple way to try to keep your model's behavior up to snuff is to make sure that it receives inputs that it expects, and that its output is something that downstream systems can handle. This can entail specifying rules that document what you expect, and either enforcing these rules (by refusing to make a prediction), or at least logging an alert that the expectations described by your validation rules have been violated. As the developer of the model, the data scientist (along with relevant subject matter experts) will often be the person in the best position to specify appropriate validation rules.\n",
    "\n",
    "In our house price prediction example, suppose you know that house prices in your market are typically in the range $750,000 to $1.5M dollars. Then you might want to set validation rules on your model pipeline to specify that you expect the model's predictions to also be in that range. Then, if the model predicts a value outside that range, the pipeline will log that one of the validation checks has failed; this allows you to investigate that instance further.\n",
    "\n",
    "Note that in this specific example, a model prediction outside the specified range may not necessarily be \"wrong\"; but out-of-range predictions are likely unusual enough that you may want to \"sanity-check\" the model's behavior in these situations.\n",
    "\n",
    "Wallaroo provides **validations** to detect anomalous data from inference inputs and outputs.  Validations are added to a Wallaroo pipeline with the `wallaroo.pipeline.add_validations` method.\n",
    "\n",
    "Adding validations takes the format:\n",
    "\n",
    "```python\n",
    "pipeline.add_validations(\n",
    "    validation_name_01 = polars.col(in|out.{column_name}) EXPRESSION,\n",
    "    validation_name_02 = polars.col(in|out.{column_name}) EXPRESSION\n",
    "    ...{additional rules}\n",
    ")\n",
    "```\n",
    "\n",
    "* `validation_name`: The user provided name of the validation.  The names must match Python variable naming requirements.\n",
    "  * **IMPORTANT NOTE**: Using the name `count` as a validation name **returns a warning**.  Any validation rules named `count` are dropped upon request and an warning returned.\n",
    "* `polars.col(in|out.{column_name})`: Specifies the **input** or **output** for a specific field aka \"column\" in an inference result.  Wallaroo inference requests are in the format `in.{field_name}` for **inputs**, and `out.{field_name}` for **outputs**.\n",
    "  * More than one field can be selected, as long as they follow the rules of the [polars 0.18 Expressions library](https://docs.pola.rs/docs/python/version/0.18/reference/expressions/index.html).\n",
    "* `EXPRESSION`:  The expression to validate. When the expression returns **True**, that indicates an anomaly detected.\n",
    "\n",
    "The [`polars` library version 0.18.5](https://docs.pola.rs/docs/python/version/0.18/index.html) is used to create the validation rule.  This is installed by default with the Wallaroo SDK.  This provides a powerful range of comparisons to organizations tracking anomalous data from their ML models.\n",
    "\n",
    "When validations are added to a pipeline, inference request outputs return the following fields:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|---|---|---|\n",
    "| **anomaly.count** | **Integer** | The total of all validations that returned **True**. |\n",
    "| **anomaly.{validation name}** | **Bool** | The output of the validation `{validation_name}`. |\n",
    "\n",
    "When validation returns `True`, **an anomaly is detected**.\n",
    "\n",
    "For example, adding the validation `fraud` to the following pipeline returns `anomaly.count` of `1` when the validation `fraud` returns `True`.  The validation `fraud` returns `True` when the **output** field **dense_1** at index **0** is greater than 0.9.\n",
    "\n",
    "```python\n",
    "sample_pipeline = wallaroo.client.build_pipeline(\"sample-pipeline\")\n",
    "sample_pipeline.add_model_step(ccfraud_model)\n",
    "\n",
    "# add the validation\n",
    "sample_pipeline.add_validations(\n",
    "    fraud=pl.col(\"out.dense_1\").list.get(0) > 0.9,\n",
    "    )\n",
    "\n",
    "# deploy the pipeline\n",
    "sample_pipeline.deploy()\n",
    "\n",
    "# sample inference\n",
    "display(sample_pipeline.infer_from_file(\"dev_high_fraud.json\", data_format='pandas-records'))\n",
    "```\n",
    "\n",
    "|&nbsp;|time|in.tensor|out.dense_1|anomaly.count|anomaly.fraud|\n",
    "|---|---|---|---|---|---|\n",
    "|0|2024-02-02 16:05:42.152|[1.0678324729, 18.1555563975, -1.6589551058, 5...]|[0.981199]|1|True|\n",
    "\n",
    "### Model Validation Rules Exercise\n",
    "\n",
    "Add some simple validation rules to the model pipeline that you created in a previous exercise.\n",
    "\n",
    "* Add an upper bound or a lower bound to the model predictions\n",
    "* Try to create predictions that fall both in and out of the specified range\n",
    "* Look through the inference results to check for detected anomalies.\n",
    "\n",
    "**HINT 1**: since the purpose of this exercise is try out validation rules, it might be a good idea to take a small data set and make predictions on that data set first, *then* set the validation rules based on those predictions, so that you can see the check failures trigger.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "```python\n",
    "import polars as pl\n",
    "\n",
    "sample_pipeline = pipeline.add_validations(\n",
    "    too_low=pl.col(\"out.main\").list.get(0) < 0.90\n",
    ")\n",
    "```\n",
    "\n",
    "For the inference request, isolate only the inferences that trigger the anomaly.  Here's one way using the DataFrame functions:\n",
    "\n",
    "```python\n",
    "# sample infer\n",
    "\n",
    "results = pipeline.infer_from_file('../data/data-1k.df.json')\n",
    "\n",
    "results.loc[results['anomaly.too_low'] == True,['time', 'out.main', 'anomaly.too_low', 'anomaly.count']].head(20)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f37a34-6caf-47a8-b569-517c17ba1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank space to set up validation rule\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank space for inferences\n",
    "\n",
    "# sample infer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5b1b7",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "At this point, if you are not continuing on to the next notebook, undeploy your pipeline to give the resources back to the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a5223-b9f6-4891-ab93-00c113b578ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank space to undeploy the pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6179b95-b0bc-4057-80ee-aa8d543f40ac",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "In this workshop you have\n",
    "\n",
    "* Set a validation rule on your house price prediction pipeline.\n",
    "* Detected model predictions that failed the validation rule.\n",
    "\n",
    "In the next notebook, you will learn how to monitor the distribution of model outputs for drift away from expected behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
