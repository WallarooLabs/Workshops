{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodel Forecast with Wallaroo Features: Data Connection\n",
    "\n",
    "Wallaroo Connections are definitions set by MLOps engineers that are used by other Wallaroo users for connection information to a data source.\n",
    "\n",
    "This provides MLOps engineers a method of creating and updating connection information for data stores:  databases, Kafka topics, etc.  Wallaroo Connections are composed of three main parts:\n",
    "\n",
    "* Name:  The unique name of the connection.\n",
    "* Type:  A user defined string that designates the type of connection.  This is used to organize connections.\n",
    "* Details:  Details are a JSON object containing the information needed to make the connection.  This can include data sources, authentication tokens, etc.\n",
    "\n",
    "Wallaroo Connections are only used to store the connection information used by other processes to create and use external connections.  The user still has to provide the libraries and other elements to actually make and use the conneciton.\n",
    "\n",
    "The primary advantage is Wallaroo connections allow scripts and other code to retrieve the connection details directly from their Wallaroo instance, then refer to those connection details.  They don't need to know what those details actually - they can refer to them in their code to make their code more flexible.\n",
    "\n",
    "For this step, we will use a Google BigQuery dataset to retrieve the inference information, predict the next month of sales, then store those predictions into another table.  This will use the Wallaroo Connection feature to create a Connection, assign it to our workspace, then perform our inferences by using the Connection details to connect to the BigQuery dataset and tables.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* A Wallaroo instance version 2023.2.1 or greater.\n",
    "* [Google Authentication Credentials](https://cloud.google.com/docs/authentication/external/set-up-adc).  This tutorial allows any authenticated Google account to view the data in the reference dataset and tables.\n",
    "\n",
    "## References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Model Uploads and Registrations: Python Models](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-upload-python/)\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)\n",
    "* [Wallaroo SDK Essentials Guide: Data Connections Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-dataconnections/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodel Forecast Connection Steps\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step is to import the libraries that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from resources import simdb\n",
    "from resources import util\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# for Big Query connections\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import db_dtypes\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.2.1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wallaroo.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "wallarooPrefix = \"doc-test.\"\n",
    "wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configurations\n",
    "\n",
    "The following will set the workspace, model name, and pipeline that will be used for this example.  If the workspace or pipeline already exist, then they will assigned for use in this example.  If they do not exist, they will be created based on the names listed below.\n",
    "\n",
    "Workspace names must be unique.  To allow this tutorial to run in the same Wallaroo instance for multiple users, set the `suffix` variable or share the workspace with other users.\n",
    "\n",
    "#### Set Configurations References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Workspace Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-workspace/)\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for unique connection names\n",
    "\n",
    "import string\n",
    "import random\n",
    "\n",
    "suffix= ''.join(random.choice(string.ascii_lowercase) for i in range(4))\n",
    "\n",
    "suffix='jch'\n",
    "\n",
    "workspace_name = f'forecast-model-workshop{suffix}'\n",
    "\n",
    "pipeline_name = 'forecast-workshop-pipeline'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Workspace and Pipeline\n",
    "\n",
    "The workspace will be either used or created if it does not exist, along with the pipeline.  The models uploaded in the Upload and Deploy tutorial are referenced in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline\n",
    "\n",
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)\n",
    "\n",
    "# Get the most recent version of a model in the workspace\n",
    "# Assumes that the most recent version is the first in the list of versions.\n",
    "# wl.get_current_workspace().models() returns a list of models in the current workspace\n",
    "\n",
    "def get_model(mname):\n",
    "    modellist = wl.get_current_workspace().models()\n",
    "    model = [m.versions()[0] for m in modellist if m.name() == mname]\n",
    "    if len(model) <= 0:\n",
    "        raise KeyError(f\"model {mname} not found in this workspace\")\n",
    "    return model[0]\n",
    "\n",
    "# upload three models:  the control and two challengers\n",
    "\n",
    "control_model_name = 'forecast-control-model'\n",
    "challenger01_model_name = 'forecast-challenger01-model'\n",
    "challenger02_model_name = 'forecast-challenger02-model'\n",
    "\n",
    "# retrieve the models\n",
    "\n",
    "bike_day_model = get_model(control_model_name)\n",
    "\n",
    "challenger_model_01 = get_model(challenger01_model_name)\n",
    "\n",
    "challenger_model_02 = get_model(challenger02_model_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Pipeline\n",
    "\n",
    "We will now add the uploaded model as a step for the pipeline, then deploy it.  The pipeline configuration will allow for multiple replicas of the pipeline to be deployed and spooled up in the cluster.  Each pipeline replica will use 0.25 cpu and 512 Gi RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>forecast-workshop-pipeline</td></tr><tr><th>created</th> <td>2023-07-27 15:54:55.416132+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-27 19:10:16.024373+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>ebdc834c-86c4-4818-8b2b-9a308d40c6ee, 08ba54b2-2674-477a-a570-da148296c85d, 2886724f-c93f-4fd1-9592-3c520c3da31c, a6d854cd-273a-462f-b9e4-397cf106aa84, 869bcedb-85f3-4fef-a111-9962a5e0d784, 02fb29d5-d5b4-4be9-adea-b6a9fa09c54c, bf0206fb-139d-4c91-84ae-ca22a42b481e, 02c8f781-adae-466f-9773-c528b05bdbce, bdfd7e4d-95e9-4c1a-b532-97178a6c2bf7, 43f1a7e2-246a-40fc-98c4-78bff1f2d674, 351736d9-07bf-4956-9724-6e135be5fcd8, dc172ae6-00f1-4cdc-8b19-591eaeb72185, 02039466-5f92-40c0-a846-2944cb0cb995, 25d73dc4-00c0-4d09-b897-f8cb7df45ec0, e3a29c1e-4922-4bd5-8fe8-55b8eed2df31, ace2bfea-1c99-45bb-bd46-236600f78e11, 404e87ac-94e2-43f8-bd75-9c7ff76ad7d2, 41298f7f-d353-49f6-ad34-ef251ea321cf</td></tr><tr><th>steps</th> <td>forecast-challenger02-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'forecast-workshop-pipeline', 'create_time': datetime.datetime(2023, 7, 27, 15, 54, 55, 416132, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'forecast-control-model', 'version': '0daa07c7-797d-429f-8a3b-7bba4f709da0', 'sha': '60156c8e9bad5b9fee1dfea2aeae05ca3f643f53b5b6d6a365e8e020c72af6ac'}]}}]\"}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the deployment to allow for additional engines to run\n",
    "# Undeploy and clear the pipeline in case it was used in other demonstrations\n",
    "pipeline.undeploy()\n",
    "pipeline.clear()\n",
    "deploy_config = (wallaroo.DeploymentConfigBuilder()\n",
    "                        .replica_count(1)\n",
    "                        .replica_autoscale_min_max(minimum=2, maximum=5)\n",
    "                        .cpus(0.25)\n",
    "                        .memory(\"512Mi\")\n",
    "                        .build()\n",
    "                    )\n",
    "\n",
    "pipeline.add_model_step(bike_day_model)\n",
    "# pipeline.add_model_step(step)\n",
    "pipeline.deploy(deployment_config = deploy_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Connection\n",
    "\n",
    "The details of the connection are stored in the file `./resources/bigquery_service_account_statsmodel.json` that include the credentials to connect to a public Big Query dataset.  For this example, any credentials for a Google account are sufficient to access this sample dataset and tables.\n",
    "\n",
    "With the credentials are three other important fields:\n",
    "\n",
    "* `dataset`: The BigQuery dataset from the project specified in the service account credentials file.\n",
    "* `input_table`: The table used for inference inputs.\n",
    "* `output_table`: The table used to store results.\n",
    "\n",
    "The details on how to generate the table and data for the sample `bike_rentals` table are stored in the file `./resources/create_bike_rentals.table`, with the data used stored in `./resources/bike_rentals.csv`.\n",
    "\n",
    "Wallaroo connections are created through the Wallaroo Client `create_connection(name, type, details)` method.  See the [Wallaroo SDK Essentials Guide: Data Connections Management guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-dataconnections/) for full details.\n",
    "\n",
    "Wallaroo connections are retrieved with the Wallaroo Client `get_connection`\n",
    "\n",
    "Note that connection names must be unique across the Wallaroo instance.  The sample code below assumes that the connection with the same name was either previously created with the proper credentials, or will be created through this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the connection information for other steps\n",
    "\n",
    "forecast_connection_input_name = f'statsmodel-bike-rentals-{suffix}'\n",
    "forecast_connection_input_type = \"BIGQUERY\"\n",
    "forecast_connection_input_argument = json.load(open('./resources/bigquery_service_account_statsmodel.json.example'))\n",
    "\n",
    "# if the connection with the same name exists, use it.  Otherwise, create it.\n",
    "def get_connection(name, type, details):\n",
    "    connection = None\n",
    "    for cn in wl.list_connections():\n",
    "        if cn.name() == name:\n",
    "            connection= cn\n",
    "    if(connection == None):\n",
    "        connection = wl.create_connection(name=name, \n",
    "                                         connection_type=type, \n",
    "                                         details=details)\n",
    "    return connection\n",
    "\n",
    "\n",
    "statsmodel_connection = get_connection(forecast_connection_input_name,\n",
    "                                       forecast_connection_input_type,\n",
    "                                       forecast_connection_input_argument)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Connection to Workspace\n",
    "\n",
    "We'll now add the connection to our workspace so it can be retrieved by other workspace users.  The method Workspace `add_connection(connection_name)` adds a Data Connection to a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th><th>connection type</th><th>details</th><th>created at</th><th>linked workspaces</th></tr><tr><td>statsmodel-bike-rentals-jch</td><td>BIGQUERY</td><td>*****</td><td>2023-07-27T18:54:43.671521+00:00</td><td>['forecast-model-workshopjch']</td></tr></table>"
      ],
      "text/plain": [
       "[<wallaroo.connection.Connection at 0x171a739d0>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.add_connection(forecast_connection_input_name)\n",
    "workspace.list_connections()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Connection from Workspace\n",
    "\n",
    "To simulate a data scientist's procedural flow, we'll now retrieve the connection from the workspace.\n",
    "\n",
    "The method Workspace `list_connections()` displays a list of connections attached to the workspace. By default the details field is obfuscated.  Specific connections are retrieved by specifying their position in the returned list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "          <tr>\n",
       "            <th>Field</th>\n",
       "            <th>Value</th>\n",
       "          </tr>\n",
       "          <tr>\n",
       "            <td>Name</td><td>statsmodel-bike-rentals-jch</td>\n",
       "          </tr>\n",
       "          <tr>\n",
       "            <td>Connection Type</td><td>BIGQUERY</td>\n",
       "          </tr>\n",
       "          <tr>\n",
       "            <td>Details</td><td>*****</td>\n",
       "          </tr>\n",
       "          <tr>\n",
       "            <td>Created At</td><td>2023-07-27T18:54:43.671521+00:00</td>\n",
       "          </tr>\n",
       "          <tr>\n",
       "            <td>Linked Workspaces</td><td>['forecast-model-workshopjch']</td>\n",
       "          </tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<wallaroo.connection.Connection at 0x128f4f6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forecast_connection = workspace.list_connections()[0]\n",
    "display(forecast_connection)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference from BigQuery Table\n",
    "\n",
    "We'll now retrieve sample data through the Wallaroo connection, and perform a sample inference.  The connection details are retrieved through the Connection `details()` method.\n",
    "\n",
    "The process is:\n",
    "\n",
    "* Create the BigQuery credentials.\n",
    "* Connect to the BigQuery dataset.\n",
    "* Retrieve the inference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery_statsmodel_credentials = service_account.Credentials.from_service_account_info(\n",
    "    forecast_connection.details())\n",
    "\n",
    "bigquery_statsmodel_client = bigquery.Client(\n",
    "    credentials=bigquery_statsmodel_credentials, \n",
    "    project=forecast_connection.details()['project_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': ['2011-01-23',\n",
       "  '2011-01-24',\n",
       "  '2011-01-25',\n",
       "  '2011-01-26',\n",
       "  '2011-01-27'],\n",
       " 'count': [986, 1416, 1985, 506, 431]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference_inputs = bigquery_statsmodel_client.query(\n",
    "        f\"\"\"\n",
    "        select dteday as date, count FROM {forecast_connection.details()['dataset']}.{forecast_connection.details()['input_table']}\n",
    "        where dteday > DATE_SUB(DATE('2011-02-22'), \n",
    "        INTERVAL 1 month) AND dteday <= DATE('2011-02-22') \n",
    "        ORDER BY dteday \n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "    ).to_dataframe().apply({\"date\":str, \"count\":int}).to_dict(orient='list')\n",
    "\n",
    "# the original table sends back the date schema as a date, not text.  We'll convert it here.\n",
    "\n",
    "# inference_inputs = inference_inputs.apply({\"date\":str, \"cnt\":int})\n",
    "\n",
    "display(inference_inputs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Inference from BigQuery Connection Data\n",
    "\n",
    "With the data retrieved, we'll perform an inference through it and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1177, 1023, 1082, 1060, 1068, 1065, 1066]}]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pipeline.infer(inference_inputs)\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Four Weeks of Inference Data\n",
    "\n",
    "Now we'll go back staring at the \"current data\" of the next month in 2011, and fetch the previous month to that date, then use that to predict what sales will be over the next 7 days.\n",
    "\n",
    "The inference data is saved into the `inference_data` List - each element in the list will be a separate inference request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6-1-2011'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start by getting the current month - we'll alway assume we're in 2011 to match the data store\n",
    "\n",
    "month = datetime.datetime.now().month\n",
    "month=5\n",
    "start_date = f\"{month+1}-1-2011\"\n",
    "display(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast_days(firstdate) :\n",
    "    days = [i*7 for i in [-1,0,1,2,3,4]]\n",
    "    deltadays = pd.to_timedelta(pd.Series(days), unit='D') \n",
    "\n",
    "    analysis_days = (pd.to_datetime(firstdate) + deltadays).dt.date\n",
    "    analysis_days = [str(day) for day in analysis_days]\n",
    "    analysis_days\n",
    "    seed_day = analysis_days.pop(0)\n",
    "\n",
    "    return analysis_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2011-06-01', '2011-06-08', '2011-06-15', '2011-06-22', '2011-06-29']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forecast_dates = get_forecast_days(start_date)\n",
    "display(forecast_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date: 2011-06-01\n",
      "\n",
      "            select count from wallaroo_workshop_public.bike_rentals where \n",
      "            dteday >= DATE_SUB(DATE('2011-06-01'), INTERVAL 1 month) \n",
      "            AND dteday < DATE('2011-06-01') \n",
      "            ORDER BY dteday\n",
      "            \n",
      "Current date: 2011-06-08\n",
      "\n",
      "            select count from wallaroo_workshop_public.bike_rentals where \n",
      "            dteday >= DATE_SUB(DATE('2011-06-08'), INTERVAL 1 month) \n",
      "            AND dteday < DATE('2011-06-08') \n",
      "            ORDER BY dteday\n",
      "            \n",
      "Current date: 2011-06-15\n",
      "\n",
      "            select count from wallaroo_workshop_public.bike_rentals where \n",
      "            dteday >= DATE_SUB(DATE('2011-06-15'), INTERVAL 1 month) \n",
      "            AND dteday < DATE('2011-06-15') \n",
      "            ORDER BY dteday\n",
      "            \n",
      "Current date: 2011-06-22\n",
      "\n",
      "            select count from wallaroo_workshop_public.bike_rentals where \n",
      "            dteday >= DATE_SUB(DATE('2011-06-22'), INTERVAL 1 month) \n",
      "            AND dteday < DATE('2011-06-22') \n",
      "            ORDER BY dteday\n",
      "            \n",
      "Current date: 2011-06-29\n",
      "\n",
      "            select count from wallaroo_workshop_public.bike_rentals where \n",
      "            dteday >= DATE_SUB(DATE('2011-06-29'), INTERVAL 1 month) \n",
      "            AND dteday < DATE('2011-06-29') \n",
      "            ORDER BY dteday\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "# get our list of items to run through\n",
    "\n",
    "inference_data = []\n",
    "days = []\n",
    "\n",
    "# get the days from the start date to the end date\n",
    "def get_forecast_dates(forecast_day: str, nforecast=7):\n",
    "    days = [i for i in range(nforecast)]\n",
    "    deltadays = pd.to_timedelta(pd.Series(days), unit='D')\n",
    "    \n",
    "    last_day = pd.to_datetime(forecast_day)\n",
    "    dates = last_day + deltadays\n",
    "    datestr = dates.dt.date.astype(str)\n",
    "    return datestr \n",
    "\n",
    "# used to generate our queries\n",
    "def mk_dt_range_query(*, tablename: str, forecast_day: str) -> str:\n",
    "    assert isinstance(tablename, str)\n",
    "    assert isinstance(forecast_day, str)\n",
    "    query = f\"\"\"\n",
    "            select count from {tablename} where \n",
    "            dteday >= DATE_SUB(DATE('{forecast_day}'), INTERVAL 1 month) \n",
    "            AND dteday < DATE('{forecast_day}') \n",
    "            ORDER BY dteday\n",
    "            \"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "for day in forecast_dates:\n",
    "    print(f\"Current date: {day}\")\n",
    "    day_range=get_forecast_dates(day)\n",
    "    days.append({\"date\": day_range})\n",
    "    query = mk_dt_range_query(tablename=f\"{forecast_connection.details()['dataset']}.{forecast_connection.details()['input_table']}\", forecast_day=day)\n",
    "    print(query)\n",
    "    data = bigquery_statsmodel_client.query(query).to_dataframe().apply({\"count\":int}).to_dict(orient='list')\n",
    "    # add the date into the list\n",
    "    inference_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count': [3351,\n",
       "   4401,\n",
       "   4451,\n",
       "   2633,\n",
       "   4433,\n",
       "   4608,\n",
       "   4714,\n",
       "   4333,\n",
       "   4362,\n",
       "   4803,\n",
       "   4182,\n",
       "   4864,\n",
       "   4105,\n",
       "   3409,\n",
       "   4553,\n",
       "   3958,\n",
       "   4123,\n",
       "   3855,\n",
       "   4575,\n",
       "   4917,\n",
       "   5805,\n",
       "   4660,\n",
       "   4274,\n",
       "   4492,\n",
       "   4978,\n",
       "   4677,\n",
       "   4679,\n",
       "   4758,\n",
       "   4788,\n",
       "   4098,\n",
       "   3982]},\n",
       " {'count': [4333,\n",
       "   4362,\n",
       "   4803,\n",
       "   4182,\n",
       "   4864,\n",
       "   4105,\n",
       "   3409,\n",
       "   4553,\n",
       "   3958,\n",
       "   4123,\n",
       "   3855,\n",
       "   4575,\n",
       "   4917,\n",
       "   5805,\n",
       "   4660,\n",
       "   4274,\n",
       "   4492,\n",
       "   4978,\n",
       "   4677,\n",
       "   4679,\n",
       "   4758,\n",
       "   4788,\n",
       "   4098,\n",
       "   3982,\n",
       "   3974,\n",
       "   4968,\n",
       "   5312,\n",
       "   5342,\n",
       "   4906,\n",
       "   4548,\n",
       "   4833]},\n",
       " {'count': [4553,\n",
       "   3958,\n",
       "   4123,\n",
       "   3855,\n",
       "   4575,\n",
       "   4917,\n",
       "   5805,\n",
       "   4660,\n",
       "   4274,\n",
       "   4492,\n",
       "   4978,\n",
       "   4677,\n",
       "   4679,\n",
       "   4758,\n",
       "   4788,\n",
       "   4098,\n",
       "   3982,\n",
       "   3974,\n",
       "   4968,\n",
       "   5312,\n",
       "   5342,\n",
       "   4906,\n",
       "   4548,\n",
       "   4833,\n",
       "   4401,\n",
       "   3915,\n",
       "   4586,\n",
       "   4966,\n",
       "   4460,\n",
       "   5020,\n",
       "   4891]},\n",
       " {'count': [4660,\n",
       "   4274,\n",
       "   4492,\n",
       "   4978,\n",
       "   4677,\n",
       "   4679,\n",
       "   4758,\n",
       "   4788,\n",
       "   4098,\n",
       "   3982,\n",
       "   3974,\n",
       "   4968,\n",
       "   5312,\n",
       "   5342,\n",
       "   4906,\n",
       "   4548,\n",
       "   4833,\n",
       "   4401,\n",
       "   3915,\n",
       "   4586,\n",
       "   4966,\n",
       "   4460,\n",
       "   5020,\n",
       "   4891,\n",
       "   5180,\n",
       "   3767,\n",
       "   4844,\n",
       "   5119,\n",
       "   4744,\n",
       "   4010,\n",
       "   4835]},\n",
       " {'count': [4788,\n",
       "   4098,\n",
       "   3982,\n",
       "   3974,\n",
       "   4968,\n",
       "   5312,\n",
       "   5342,\n",
       "   4906,\n",
       "   4548,\n",
       "   4833,\n",
       "   4401,\n",
       "   3915,\n",
       "   4586,\n",
       "   4966,\n",
       "   4460,\n",
       "   5020,\n",
       "   4891,\n",
       "   5180,\n",
       "   3767,\n",
       "   4844,\n",
       "   5119,\n",
       "   4744,\n",
       "   4010,\n",
       "   4835,\n",
       "   4507,\n",
       "   4790,\n",
       "   4991,\n",
       "   5202,\n",
       "   5305,\n",
       "   4708,\n",
       "   4648]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(inference_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Inference Example\n",
    "\n",
    "For this example, we will use the `parallel_infer` method.  This allows us to submit the entire list of inference inputs in one request.  This is an asynchronous method that will manage submitting the separate inference requests to the pipeline, then gather the results into a List of inference results.  These results will be parsed to display the entire list of results for the entire month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_results = await pipeline.parallel_infer(tensor_list=inference_data, \n",
    "                                                 timeout=20, \n",
    "                                                 num_parallel=16, \n",
    "                                                 retries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'forecast': [4373, 4385, 4379, 4382, 4380, 4381, 4380]}],\n",
       " [{'forecast': [4666, 4582, 4560, 4555, 4553, 4553, 4552]}],\n",
       " [{'forecast': [4683, 4634, 4625, 4623, 4622, 4622, 4622]}],\n",
       " [{'forecast': [4732, 4637, 4648, 4646, 4647, 4647, 4647]}],\n",
       " [{'forecast': [4692, 4698, 4699, 4699, 4699, 4699, 4699]}]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(parallel_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_results = list(zip(days, parallel_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge our parallel results into the predicted date sales\n",
    "\n",
    "# results_table = pd.DataFrame(list(zip(days, parallel_results)),\n",
    "#                             columns=[\"date\", \"forecast\"])\n",
    "results_table = pd.DataFrame(columns=[\"date\", \"forecast\"])\n",
    "\n",
    "# display(days_results)\n",
    "for date in days_results:\n",
    "    # display(date)\n",
    "    new_days = date[0]['date'].tolist()\n",
    "    new_forecast = date[1][0]['forecast']\n",
    "    new_results = list(zip(new_days, new_forecast))\n",
    "    results_table = results_table.append(pd.DataFrame(list(zip(new_days, new_forecast)), columns=['date','forecast']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on all of the predictions, here are the results for the next month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>4373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-06-02</td>\n",
       "      <td>4385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-06-03</td>\n",
       "      <td>4379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-06-04</td>\n",
       "      <td>4382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-06-05</td>\n",
       "      <td>4380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-06-06</td>\n",
       "      <td>4381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-06-07</td>\n",
       "      <td>4380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-06-08</td>\n",
       "      <td>4666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-06-09</td>\n",
       "      <td>4582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-06-10</td>\n",
       "      <td>4560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-06-11</td>\n",
       "      <td>4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-06-12</td>\n",
       "      <td>4553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-06-13</td>\n",
       "      <td>4553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-06-14</td>\n",
       "      <td>4552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-06-15</td>\n",
       "      <td>4683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-06-16</td>\n",
       "      <td>4634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-06-17</td>\n",
       "      <td>4625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-06-18</td>\n",
       "      <td>4623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-06-19</td>\n",
       "      <td>4622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-06-20</td>\n",
       "      <td>4622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-06-21</td>\n",
       "      <td>4622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-06-22</td>\n",
       "      <td>4732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-06-23</td>\n",
       "      <td>4637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-06-24</td>\n",
       "      <td>4648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-06-25</td>\n",
       "      <td>4646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-06-26</td>\n",
       "      <td>4647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-06-27</td>\n",
       "      <td>4647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-06-28</td>\n",
       "      <td>4647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-06-29</td>\n",
       "      <td>4692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>4699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-07-02</td>\n",
       "      <td>4699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-07-03</td>\n",
       "      <td>4699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-07-04</td>\n",
       "      <td>4699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-07-05</td>\n",
       "      <td>4699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date forecast\n",
       "0  2011-06-01     4373\n",
       "1  2011-06-02     4385\n",
       "2  2011-06-03     4379\n",
       "3  2011-06-04     4382\n",
       "4  2011-06-05     4380\n",
       "5  2011-06-06     4381\n",
       "6  2011-06-07     4380\n",
       "0  2011-06-08     4666\n",
       "1  2011-06-09     4582\n",
       "2  2011-06-10     4560\n",
       "3  2011-06-11     4555\n",
       "4  2011-06-12     4553\n",
       "5  2011-06-13     4553\n",
       "6  2011-06-14     4552\n",
       "0  2011-06-15     4683\n",
       "1  2011-06-16     4634\n",
       "2  2011-06-17     4625\n",
       "3  2011-06-18     4623\n",
       "4  2011-06-19     4622\n",
       "5  2011-06-20     4622\n",
       "6  2011-06-21     4622\n",
       "0  2011-06-22     4732\n",
       "1  2011-06-23     4637\n",
       "2  2011-06-24     4648\n",
       "3  2011-06-25     4646\n",
       "4  2011-06-26     4647\n",
       "5  2011-06-27     4647\n",
       "6  2011-06-28     4647\n",
       "0  2011-06-29     4692\n",
       "1  2011-06-30     4698\n",
       "2  2011-07-01     4699\n",
       "3  2011-07-02     4699\n",
       "4  2011-07-03     4699\n",
       "5  2011-07-04     4699\n",
       "6  2011-07-05     4699"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "Undeploy the pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>forecast-workshop-pipeline</td></tr><tr><th>created</th> <td>2023-07-27 15:54:55.416132+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-27 19:10:16.024373+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>ebdc834c-86c4-4818-8b2b-9a308d40c6ee, 08ba54b2-2674-477a-a570-da148296c85d, 2886724f-c93f-4fd1-9592-3c520c3da31c, a6d854cd-273a-462f-b9e4-397cf106aa84, 869bcedb-85f3-4fef-a111-9962a5e0d784, 02fb29d5-d5b4-4be9-adea-b6a9fa09c54c, bf0206fb-139d-4c91-84ae-ca22a42b481e, 02c8f781-adae-466f-9773-c528b05bdbce, bdfd7e4d-95e9-4c1a-b532-97178a6c2bf7, 43f1a7e2-246a-40fc-98c4-78bff1f2d674, 351736d9-07bf-4956-9724-6e135be5fcd8, dc172ae6-00f1-4cdc-8b19-591eaeb72185, 02039466-5f92-40c0-a846-2944cb0cb995, 25d73dc4-00c0-4d09-b897-f8cb7df45ec0, e3a29c1e-4922-4bd5-8fe8-55b8eed2df31, ace2bfea-1c99-45bb-bd46-236600f78e11, 404e87ac-94e2-43f8-bd75-9c7ff76ad7d2, 41298f7f-d353-49f6-ad34-ef251ea321cf</td></tr><tr><th>steps</th> <td>forecast-challenger02-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'forecast-workshop-pipeline', 'create_time': datetime.datetime(2023, 7, 27, 15, 54, 55, 416132, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'forecast-control-model', 'version': '0daa07c7-797d-429f-8a3b-7bba4f709da0', 'sha': '60156c8e9bad5b9fee1dfea2aeae05ca3f643f53b5b6d6a365e8e020c72af6ac'}]}}]\"}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
