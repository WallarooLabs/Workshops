{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodel Forecast with Wallaroo Features: Deploy and Test Infer\n",
    "\n",
    "This tutorial series demonstrates how to use Wallaroo to deploy a statsmodel ARIMA forecast model and perform sample inferences through it.\n",
    "\n",
    "In the previous step \"Statsmodel Forecast with Wallaroo Features: Model Creation\", the statsmodel was trained and saved to the Python file `forecast.py`.  This file will now be uploaded to a Wallaroo instance as a Python model, then used for sample inferences.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* A Wallaroo instance version 2023.2.1 or greater.\n",
    "\n",
    "## References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Model Uploads and Registrations: Python Models](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-upload-python/)\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)\n",
    "* [Wallaroo SDK Essentials: Inference Guide: Parallel Inferences](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-inferences/#parallel-inferences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Steps\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step is to import the libraries that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.2.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wallaroo.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "# wallarooPrefix = \"doc-test.\"\n",
    "# wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "wallarooPrefix = \"product-uat-ee.\"\n",
    "wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configurations\n",
    "\n",
    "The following will set the workspace, model name, and pipeline that will be used for this example.  If the workspace or pipeline already exist, then they will assigned for use in this example.  If they do not exist, they will be created based on the names listed below.\n",
    "\n",
    "Workspace names must be unique.  To allow this tutorial to run in the same Wallaroo instance for multiple users, set the `suffix` variable or share the workspace with other users.\n",
    "\n",
    "#### Set Configurations References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Workspace Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-workspace/)\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for unique connection names\n",
    "\n",
    "# import string\n",
    "# import random\n",
    "\n",
    "# suffix= ''.join(random.choice(string.ascii_lowercase) for i in range(4))\n",
    "\n",
    "suffix='jch4'\n",
    "\n",
    "workspace_name = f'forecast-model-workshop{suffix}'\n",
    "\n",
    "pipeline_name = 'forecast-workshop-pipeline'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Workspace and Pipeline\n",
    "\n",
    "The workspace will be either used or created if it does not exist, along with the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline\n",
    "\n",
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Model\n",
    "\n",
    "The Python model created in \"Forecast and Parallel Infer with Statsmodel: Model Creation\" will now be uploaded.  Note that the Framework is set to `Framework.PYTHON` to inform the Wallaroo engine on what model framework is being added.\n",
    "\n",
    "The other versions of the model are also uploaded in this step to show how to hot swap between models and other uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload three models:  the control and two challengers\n",
    "\n",
    "control_model_name = 'forecast-control-model'\n",
    "control_model_file = './forecast_standard.py'\n",
    "\n",
    "challenger01_model_name = 'forecast-challenger01-model'\n",
    "challenger01_model_file = './forecast_alternate01.py'\n",
    "\n",
    "challenger02_model_name = 'forecast-challenger02-model'\n",
    "challenger02_model_file = './forecast_alternate02.py'\n",
    "\n",
    "# Holding on these for later\n",
    "# input_schema = pa.schema([\n",
    "#     pa.field('count', pa.list_(pa.int64(), list_size=7))\n",
    "# ])\n",
    "\n",
    "input_schema = pa.schema([\n",
    "    pa.field('count', pa.int64())\n",
    "])\n",
    "# output_schema = pa.schema([\n",
    "#     pa.field('forecast', pa.list_(pa.int64()))\n",
    "# ])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('forecast', pa.int64())\n",
    "])\n",
    "\n",
    "# upload the models\n",
    "\n",
    "bike_day_model = wl.upload_model(control_model_name, \n",
    "                                 control_model_file, \n",
    "                                 input_schema=input_schema,\n",
    "                                 output_schema=output_schema,\n",
    "                                 framework = Framework.PYTHON)\n",
    "\n",
    "# bike_day_model = wl.upload_model(control_model_name, control_model_file, Framework.PYTHON)\n",
    "\n",
    "# challenger_model_01 = wl.upload_model(challenger01_model_name, challenger01_model_file, Framework.PYTHON)\n",
    "\n",
    "# challenger_model_02 = wl.upload_model(challenger02_model_name, challenger02_model_file, Framework.PYTHON)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Pipeline\n",
    "\n",
    "We will now add the uploaded model as a step for the pipeline, then deploy it.\n",
    "\n",
    "Until a pipeline is deployed, the steps assigned to it only exist in the local memory.  During deployment the pipeline steps, configurations, and other details are set in the database, and resources allocated from the cluster for the pipeline's use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>*** An error occurred while deploying your pipeline.</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "WaitForDeployError",
     "evalue": "Deployment failed. See status for details.\nStatus: {'status': 'Error', 'details': [], 'engines': [{'ip': None, 'name': 'engine-576b794cff-dpcjl', 'status': 'Pending', 'reason': '0/9 nodes are available: 9 Insufficient cpu. preemption: 0/9 nodes are available: 9 No preemption victims found for incoming pod.', 'details': ['0/9 nodes are available: 9 Insufficient cpu. preemption: 0/9 nodes are available: 9 No preemption victims found for incoming pod.'], 'pipeline_statuses': None, 'model_statuses': None}], 'engine_lbs': [{'ip': '10.244.8.3', 'name': 'engine-lb-584f54c899-2vmsj', 'status': 'Running', 'reason': None, 'details': []}], 'sidekicks': []}",
     "output_type": "error",
     "traceback": [
      "Deployment failed. See status for details.\nStatus: {'status': 'Error', 'details': [], 'engines': [{'ip': None, 'name': 'engine-576b794cff-dpcjl', 'status': 'Pending', 'reason': '0/9 nodes are available: 9 Insufficient cpu. preemption: 0/9 nodes are available: 9 No preemption victims found for incoming pod.', 'details': ['0/9 nodes are available: 9 Insufficient cpu. preemption: 0/9 nodes are available: 9 No preemption victims found for incoming pod.'], 'pipeline_statuses': None, 'model_statuses': None}], 'engine_lbs': [{'ip': '10.244.8.3', 'name': 'engine-lb-584f54c899-2vmsj', 'status': 'Running', 'reason': None, 'details': []}], 'sidekicks': []}"
     ]
    }
   ],
   "source": [
    "# Set the deployment to allow for additional engines to run\n",
    "# Undeploy and clear the pipeline in case it was used in other demonstrations\n",
    "pipeline.undeploy()\n",
    "pipeline.clear()\n",
    "deploy_config = (wallaroo.DeploymentConfigBuilder()\n",
    "                        .replica_count(1)\n",
    "                        .replica_autoscale_min_max(minimum=2, maximum=5)\n",
    "                        .cpus(0.25)\n",
    "                        .memory(\"512Mi\")\n",
    "                        .build()\n",
    "                    )\n",
    "\n",
    "pipeline.add_model_step(bike_day_model)\n",
    "# pipeline.add_model_step(step)\n",
    "# pipeline.deploy(deployment_config = deploy_config)\n",
    "pipeline.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ModelInference': {'models': [{'name': 'forecast-control-model', 'version': '14df2c41-91e4-4077-ad82-2ed6e298132b', 'sha': '4e4d344bc5496817092f550e664eee0445051e2dcce4527c6c2dbe6685275a90'}]}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference\n",
    "\n",
    "Run a test inference to verify the pipeline is operational from the sample test data stored in `./data/testdata_dict.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jf/_cj0q9d51s365wksymljdz4h0000gn/T/ipykernel_27982/3167352677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minference_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# display(results)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.8/site-packages/wallaroo/pipeline.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupdate_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             self._last_infer_time = max(\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.8/site-packages/wallaroo/pipeline.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, tensor, timeout, dataset, dataset_exclude, dataset_separator)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mdeployment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deployment_for_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeployment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             return deployment.infer(\n\u001b[0m\u001b[1;32m    666\u001b[0m                 \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_exclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_separator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             )\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.8/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, tensor, timeout, dataset, dataset_exclude, dataset_separator)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 )\n\u001b[1;32m    680\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_with_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_with_arrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.8/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36m_infer_with_pandas\u001b[0;34m(self, tensor, params, timeout)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Infer response is not valid.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ms\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"check_failures\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"check_failures\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhack_pandas_dataframe_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time'"
     ]
    }
   ],
   "source": [
    "inferencedata = pd.read_json('./data/testdata_standard.df.json')\n",
    "# display(inferencedata)\n",
    "\n",
    "# display(pa.Schema.from_pandas(inferencedata))\n",
    "\n",
    "inference_frame = pd.DataFrame({\"count\": [15]})\n",
    "\n",
    "results = pipeline.infer(inference_frame)\n",
    "\n",
    "# display(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "Undeploy the pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>forecast-workshop-pipeline</td></tr><tr><th>created</th> <td>2023-07-27 21:04:23.296526+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-27 21:04:23.296526+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>99154217-cc5d-4458-8061-be427767e988</td></tr><tr><th>steps</th> <td>forecast-control-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'forecast-workshop-pipeline', 'create_time': datetime.datetime(2023, 7, 27, 21, 4, 23, 296526, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'forecast-control-model', 'version': '14df2c41-91e4-4077-ad82-2ed6e298132b', 'sha': '4e4d344bc5496817092f550e664eee0445051e2dcce4527c6c2dbe6685275a90'}]}}]\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
