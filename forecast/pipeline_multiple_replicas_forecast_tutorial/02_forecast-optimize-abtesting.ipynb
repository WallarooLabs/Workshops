{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodel Forecast AB Testing\n",
    "\n",
    "A/B Testing is one method of models against each other.  This demonstration will show how to use the Wallaroo pipeline step `add_random_split` and `replace_with_random_split` to randomly submit inference input data into control and challenger models.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* A Wallaroo instance version 2023.2.1 or greater.\n",
    "\n",
    "## References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Model Uploads and Registrations: Python Models](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-upload-python/)\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)\n",
    "* [Wallaroo SDK Essentials: Inference Guide: Parallel Inferences](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-inferences/#parallel-inferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B Testing\n",
    "\n",
    "A/B testing is a method that provides the ability to test out ML models for performance, accuracy or other useful benchmarks.  A/B testing is contrasted with the Wallaroo Shadow Deployment feature.  In both cases, two sets of models are added to a pipeline step:\n",
    "\n",
    "* Control or Champion model:  The model currently used for inferences.\n",
    "* Challenger model(s): One or more models that are to be compared to the champion model.\n",
    "\n",
    "The two feature are different in this way:\n",
    "\n",
    "| Feature | Description |\n",
    "|---|---|\n",
    "| A/B Testing | A subset of inferences are submitted to either the champion ML model or a challenger ML model. |\n",
    "| Shadow Deploy | All inferences are submitted to the champion model and one or more challenger models. |\n",
    "\n",
    "Wallaroo implements A/B testing via a pipeline step as either `wallaroo.pipeline.add_random_split` to set a new pipeline step or `wallaroo.pipeline.replace_with_random_split` to replace an existing step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Steps\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step is to import the libraries that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from resources import simdb\n",
    "from resources import util\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.2.1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wallaroo.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "wallarooPrefix = \"doc-test.\"\n",
    "wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configurations\n",
    "\n",
    "The following will set the workspace, model name, and pipeline that will be used for this example.  If the workspace or pipeline already exist, then they will assigned for use in this example.  If they do not exist, they will be created based on the names listed below.\n",
    "\n",
    "Workspace names must be unique.  To allow this tutorial to run in the same Wallaroo instance for multiple users, set the `suffix` variable or share the workspace with other users.\n",
    "\n",
    "#### Set Configurations References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Workspace Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-workspace/)\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for unique connection names\n",
    "\n",
    "suffix='jch'\n",
    "\n",
    "workspace_name = f'forecast-model-workshop{suffix}'\n",
    "\n",
    "pipeline_name = 'forecast-workshop-pipeline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Workspace, Pipeline and Models\n",
    "\n",
    "The workspace will be either used or created if it does not exist, along with the pipeline.\n",
    "\n",
    "The models were uploaded in the Upload and Deploy notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline\n",
    "\n",
    "# Get the most recent version of a model in the workspace\n",
    "# Assumes that the most recent version is the first in the list of versions.\n",
    "# wl.get_current_workspace().models() returns a list of models in the current workspace\n",
    "\n",
    "def get_model(mname):\n",
    "    modellist = wl.get_current_workspace().models()\n",
    "    model = [m.versions()[0] for m in modellist if m.name() == mname]\n",
    "    if len(model) <= 0:\n",
    "        raise KeyError(f\"model {mname} not found in this workspace\")\n",
    "    return model[0]\n",
    "\n",
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)\n",
    "\n",
    "# upload three models:  the control and two challengers\n",
    "\n",
    "control_model_name = 'forecast-control-model'\n",
    "challenger01_model_name = 'forecast-challenger01-model'\n",
    "challenger02_model_name = 'forecast-challenger02-model'\n",
    "\n",
    "# upload the models\n",
    "\n",
    "bike_day_model = get_model(control_model_name)\n",
    "\n",
    "challenger_model_01 = get_model(challenger01_model_name)\n",
    "\n",
    "challenger_model_02 = get_model(challenger02_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Pipeline\n",
    "\n",
    "We will now add the uploaded model as a step for the pipeline, then deploy it.  The pipeline configuration will allow for multiple replicas of the pipeline to be deployed and spooled up in the cluster.  Each pipeline replica will use 0.25 cpu and 512 Gi RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>forecast-workshop-pipeline</td></tr><tr><th>created</th> <td>2023-07-27 15:54:55.416132+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-27 16:08:39.633323+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>dc172ae6-00f1-4cdc-8b19-591eaeb72185, 02039466-5f92-40c0-a846-2944cb0cb995, 25d73dc4-00c0-4d09-b897-f8cb7df45ec0, e3a29c1e-4922-4bd5-8fe8-55b8eed2df31, ace2bfea-1c99-45bb-bd46-236600f78e11, 404e87ac-94e2-43f8-bd75-9c7ff76ad7d2, 41298f7f-d353-49f6-ad34-ef251ea321cf</td></tr><tr><th>steps</th> <td>forecast-challenger02-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'forecast-workshop-pipeline', 'create_time': datetime.datetime(2023, 7, 27, 15, 54, 55, 416132, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'forecast-control-model', 'version': '0daa07c7-797d-429f-8a3b-7bba4f709da0', 'sha': '60156c8e9bad5b9fee1dfea2aeae05ca3f643f53b5b6d6a365e8e020c72af6ac'}]}}]\"}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the deployment to allow for additional engines to run\n",
    "# Undeploy and clear the pipeline in case it was used in other demonstrations\n",
    "pipeline.undeploy()\n",
    "pipeline.clear()\n",
    "deploy_config = (wallaroo.DeploymentConfigBuilder()\n",
    "                        .replica_count(1)\n",
    "                        .replica_autoscale_min_max(minimum=2, maximum=5)\n",
    "                        .cpus(0.25)\n",
    "                        .memory(\"512Mi\")\n",
    "                        .build()\n",
    "                    )\n",
    "\n",
    "pipeline.add_model_step(bike_day_model)\n",
    "# pipeline.add_model_step(step)\n",
    "pipeline.deploy(deployment_config = deploy_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference\n",
    "\n",
    "Run a test inference to verify the pipeline is operational from the sample test data stored in `./data/testdata_dict.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1764, 1749, 1743, 1741, 1740, 1740, 1740]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inferencedata = json.load(open(\"./data/testdata_dict.json\"))\n",
    "\n",
    "results = pipeline.infer(inferencedata)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create A/B Step\n",
    "\n",
    "Here we will configure a pipeline with two models and set the control model with a random split chance of receiving 2/3 of the data.  Because this is a random split, it is possible for one model or the other to receive more inferences than a strict 2:1 ratio, but the more inferences are run, the more likely it is for the proper ratio split.\n",
    "\n",
    "The control model was already set as a python step, so we will be replacing it with the random split step, then deploying the pipeline to set the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>forecast-workshop-pipeline</td></tr><tr><th>created</th> <td>2023-07-27 15:54:55.416132+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-27 16:09:26.962727+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>351736d9-07bf-4956-9724-6e135be5fcd8, dc172ae6-00f1-4cdc-8b19-591eaeb72185, 02039466-5f92-40c0-a846-2944cb0cb995, 25d73dc4-00c0-4d09-b897-f8cb7df45ec0, e3a29c1e-4922-4bd5-8fe8-55b8eed2df31, ace2bfea-1c99-45bb-bd46-236600f78e11, 404e87ac-94e2-43f8-bd75-9c7ff76ad7d2, 41298f7f-d353-49f6-ad34-ef251ea321cf</td></tr><tr><th>steps</th> <td>forecast-challenger02-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'forecast-workshop-pipeline', 'create_time': datetime.datetime(2023, 7, 27, 15, 54, 55, 416132, tzinfo=tzutc()), 'definition': \"[{'RandomSplit': {'hash_key': 'session_id', 'weights': [{'model': {'name': 'forecast-control-model', 'version': '0daa07c7-797d-429f-8a3b-7bba4f709da0', 'sha': '60156c8e9bad5b9fee1dfea2aeae05ca3f643f53b5b6d6a365e8e020c72af6ac'}, 'weight': 2}, {'model': {'name': 'forecast-challenger01-model', 'version': '6d59e8d7-a9c9-47c4-b872-ba6c9f25f0d9', 'sha': '5e00b7106b4a07f85c14bcaaf62b05aa775448918f6446f4d834ab103dd1aa67'}, 'weight': 1}, {'model': {'name': 'forecast-challenger02-model', 'version': '1a82f4f2-df82-440a-a7de-e1c82b89df7f', 'sha': 'a842d79746a91eacd1fef9bcf2de5c2d29dcb0dab0770e27ce0e402eb03f1370'}, 'weight': 1}]}}]\"}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.replace_with_random_split(0, \n",
    "                                   [(2, bike_day_model), \n",
    "                                    (1, challenger_model_01), \n",
    "                                    (1, challenger_model_02)], \n",
    "                                    \"session_id\"\n",
    "                                    )\n",
    "pipeline.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference via Random Split\n",
    "\n",
    "A sample inference will be run.  Because this is a model that accepts JSON as the input and outputs, we will not see which model was used in the inference results.\n",
    "\n",
    "For the later log steps, we will run the inference 10 times to view the results, and how they change with the same input depending on which model the inference request is submitted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1814, 1814, 1814, 1814, 1814, 1814, 1814]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1814, 1814, 1814, 1814, 1814, 1814, 1814]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1814, 1814, 1814, 1814, 1814, 1814, 1814]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1764, 1749, 1743, 1741, 1740, 1740, 1740]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1814, 1814, 1814, 1814, 1814, 1814, 1814]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1703, 1757, 1737, 1744, 1742, 1743, 1742]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1814, 1814, 1814, 1814, 1814, 1814, 1814]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1764, 1749, 1743, 1741, 1740, 1740, 1740]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1703, 1757, 1737, 1744, 1742, 1743, 1742]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1703, 1757, 1737, 1744, 1742, 1743, 1742]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inferencedata = json.load(open(\"./data/testdata_dict.json\"))\n",
    "\n",
    "for i in range(10):\n",
    "    results = pipeline.infer(inferencedata)\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view what model was used for the inference, we look at the pipeline logs with the dataset `metadata` to retrieve additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will retrieves the `model_name` parameter from the `metadata.last_model` metadata.  This will allow us to easily identify which model was used with which inference request and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_model(df: pd.DataFrame):\n",
    "    return df['metadata.last_model'].apply(lambda x: json.loads(x)['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: There are more logs available. Please set a larger limit or request a file using export_logs."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out.json</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-27 16:10:05.054</td>\n",
       "      <td>{\"forecast\":[1703,1757,1737,1744,1742,1743,1742]}</td>\n",
       "      <td>forecast-challenger01-model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-27 16:10:04.648</td>\n",
       "      <td>{\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}</td>\n",
       "      <td>forecast-control-model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-27 16:10:03.806</td>\n",
       "      <td>{\"forecast\":[1703,1757,1737,1744,1742,1743,1742]}</td>\n",
       "      <td>forecast-challenger01-model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-27 16:10:02.480</td>\n",
       "      <td>{\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}</td>\n",
       "      <td>forecast-challenger02-model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-27 16:10:02.056</td>\n",
       "      <td>{\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}</td>\n",
       "      <td>forecast-challenger02-model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-27 16:10:01.618</td>\n",
       "      <td>{\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}</td>\n",
       "      <td>forecast-challenger02-model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-07-27 16:07:07.019</td>\n",
       "      <td>{\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}</td>\n",
       "      <td>forecast-challenger02-model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-07-27 16:07:06.582</td>\n",
       "      <td>{\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}</td>\n",
       "      <td>forecast-control-model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-07-27 16:07:06.149</td>\n",
       "      <td>{\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}</td>\n",
       "      <td>forecast-control-model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-07-27 16:07:05.268</td>\n",
       "      <td>{\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}</td>\n",
       "      <td>forecast-control-model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time                                           out.json  \\\n",
       "0 2023-07-27 16:10:05.054  {\"forecast\":[1703,1757,1737,1744,1742,1743,1742]}   \n",
       "1 2023-07-27 16:10:04.648  {\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}   \n",
       "2 2023-07-27 16:10:03.806  {\"forecast\":[1703,1757,1737,1744,1742,1743,1742]}   \n",
       "3 2023-07-27 16:10:02.480  {\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}   \n",
       "4 2023-07-27 16:10:02.056  {\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}   \n",
       "5 2023-07-27 16:10:01.618  {\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}   \n",
       "6 2023-07-27 16:07:07.019  {\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}   \n",
       "7 2023-07-27 16:07:06.582  {\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}   \n",
       "8 2023-07-27 16:07:06.149  {\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}   \n",
       "9 2023-07-27 16:07:05.268  {\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}   \n",
       "\n",
       "                         model  \n",
       "0  forecast-challenger01-model  \n",
       "1       forecast-control-model  \n",
       "2  forecast-challenger01-model  \n",
       "3  forecast-challenger02-model  \n",
       "4  forecast-challenger02-model  \n",
       "5  forecast-challenger02-model  \n",
       "6  forecast-challenger02-model  \n",
       "7       forecast-control-model  \n",
       "8       forecast-control-model  \n",
       "9       forecast-control-model  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = pipeline.logs(limit=10, dataset=[\"time\", \"out.json\",\"metadata\"])\n",
    "logs['model'] = get_log_model(logs)\n",
    "\n",
    "logs.loc[:, [\"time\", \"out.json\", \"model\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "Undeploy the pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>forecast-workshop-pipeline</td></tr><tr><th>created</th> <td>2023-07-27 15:54:55.416132+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-27 16:09:26.962727+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>351736d9-07bf-4956-9724-6e135be5fcd8, dc172ae6-00f1-4cdc-8b19-591eaeb72185, 02039466-5f92-40c0-a846-2944cb0cb995, 25d73dc4-00c0-4d09-b897-f8cb7df45ec0, e3a29c1e-4922-4bd5-8fe8-55b8eed2df31, ace2bfea-1c99-45bb-bd46-236600f78e11, 404e87ac-94e2-43f8-bd75-9c7ff76ad7d2, 41298f7f-d353-49f6-ad34-ef251ea321cf</td></tr><tr><th>steps</th> <td>forecast-challenger02-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'forecast-workshop-pipeline', 'create_time': datetime.datetime(2023, 7, 27, 15, 54, 55, 416132, tzinfo=tzutc()), 'definition': \"[{'RandomSplit': {'hash_key': 'session_id', 'weights': [{'model': {'name': 'forecast-control-model', 'version': '0daa07c7-797d-429f-8a3b-7bba4f709da0', 'sha': '60156c8e9bad5b9fee1dfea2aeae05ca3f643f53b5b6d6a365e8e020c72af6ac'}, 'weight': 2}, {'model': {'name': 'forecast-challenger01-model', 'version': '6d59e8d7-a9c9-47c4-b872-ba6c9f25f0d9', 'sha': '5e00b7106b4a07f85c14bcaaf62b05aa775448918f6446f4d834ab103dd1aa67'}, 'weight': 1}, {'model': {'name': 'forecast-challenger02-model', 'version': '1a82f4f2-df82-440a-a7de-e1c82b89df7f', 'sha': 'a842d79746a91eacd1fef9bcf2de5c2d29dcb0dab0770e27ce0e402eb03f1370'}, 'weight': 1}]}}]\"}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
