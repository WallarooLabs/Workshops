{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodel Forecast AB Testing\n",
    "\n",
    "A/B  Testing is one method of models against each other.  This demonstration will show how to use the Wallaroo pipeline step `add_random_split` and `replace_with_random_split` to randomly submit inference input data into control and challenger models.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* A Wallaroo instance version 2023.2.1 or greater.\n",
    "\n",
    "## References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Model Uploads and Registrations: Python Models](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-upload-python/)\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)\n",
    "* [Wallaroo SDK Essentials: Inference Guide: Parallel Inferences](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-inferences/#parallel-inferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shadow Deploy\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step is to import the libraries that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from resources import simdb\n",
    "from resources import util\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.2.1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wallaroo.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize connection\n",
    "\n",
    "Start a connect to the Wallaroo instance and save the connection into the variable `wl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "wallarooPrefix = \"doc-test.\"\n",
    "wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configurations\n",
    "\n",
    "The following will set the workspace, model name, and pipeline that will be used for this example.  If the workspace or pipeline already exist, then they will assigned for use in this example.  If they do not exist, they will be created based on the names listed below.\n",
    "\n",
    "Workspace names must be unique.  To allow this tutorial to run in the same Wallaroo instance for multiple users, the `suffix` variable is generated from a random set of 4 ASCII characters.  To use the same workspace across the tutorial notebooks, hard code `suffix` and verify the workspace name created is is unique across the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for unique connection names\n",
    "\n",
    "suffix='-jch2'\n",
    "\n",
    "workspace_name = f'forecast-model-workshop{suffix}'\n",
    "\n",
    "pipeline_name = 'forecast-workshop-pipeline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Workspace and Pipeline\n",
    "\n",
    "The workspace will be either used or created if it does not exist, along with the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline\n",
    "\n",
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Model\n",
    "\n",
    "The Python model created in \"Forecast and Parallel Infer with Statsmodel: Model Creation\" will now be uploaded.  Note that the Framework and runtime are set to `python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload three models:  the control and two challengers\n",
    "\n",
    "control_model_name = 'forecast-control-model'\n",
    "control_model_file = './forecast_standard.py'\n",
    "\n",
    "challenger01_model_name = 'forecast-challenger01-model'\n",
    "challenger01_model_file = './forecast_alternate01.py'\n",
    "\n",
    "challenger02_model_name = 'forecast-challenger02-model'\n",
    "challenger02_model_file = './forecast_alternate02.py'\n",
    "\n",
    "# upload the models\n",
    "\n",
    "control_model = wl.upload_model(control_model_name, control_model_file, Framework.PYTHON).configure(runtime=\"python\")\n",
    "\n",
    "challenger_model_01 = wl.upload_model(challenger01_model_name, challenger01_model_file, Framework.PYTHON).configure(runtime=\"python\")\n",
    "\n",
    "challenger_model_02 = wl.upload_model(challenger02_model_name, challenger02_model_file, Framework.PYTHON).configure(runtime=\"python\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Pipeline\n",
    "\n",
    "We will now add the uploaded model as a step for the pipeline, then deploy it.  The pipeline configuration will allow for multiple replicas of the pipeline to be deployed and spooled up in the cluster.  Each pipeline replica will use 0.25 cpu and 512 Gi RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>forecast-workshop-pipeline</td></tr><tr><th>created</th> <td>2023-07-26 19:38:56.059951+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-26 20:59:02.808182+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>276d2c5e-a96f-48e6-8158-a18a68e3bd59, 5bf788b1-fa77-4fdb-a837-409af9c19e2d, 4b529632-8f30-4ae6-a588-8bca3971f20f, 659821ab-d0ad-40c2-984f-5052757c0782, 8dcf0175-07a3-4df3-8289-7b950a1de32b</td></tr><tr><th>steps</th> <td>forecast-challenger02-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'forecast-workshop-pipeline', 'create_time': datetime.datetime(2023, 7, 26, 19, 38, 56, 59951, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'forecast-control-model', 'version': 'f6165bb1-18c0-4bcb-a6c1-4aed8db53107', 'sha': '525ea2be4402725878382631c2c32b2e3f105bf78eedf41f3ac6d71c0dfa986b'}]}}]\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the deployment to allow for additional engines to run\n",
    "pipeline.clear()\n",
    "pipeline.add_model_step(control_model)\n",
    "pipeline.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference\n",
    "For this example, we will forecast bike rentals by looking back one month from \"today\" which will be set as 2011-02-22.  The data from 2011-01-23 to 2011-01-27 (the 5 days starting from one month back) are used to generate a forecast for what bike sales will be over the next week from \"today\", which will be 2011-02-23 to 2011-03-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1764, 1749, 1743, 1741, 1740, 1740, 1740]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inferencedata = json.load(open(\"./data/testdata_dict.json\"))\n",
    "\n",
    "results = pipeline.infer(inferencedata)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Pipeline Step with Random Step\n",
    "\n",
    "A 2:1:1 weighted random split - control will get 50% of the inference requests, the other two models 25% each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>forecast-workshop-pipeline</td></tr><tr><th>created</th> <td>2023-07-26 19:38:56.059951+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-26 20:59:22.730271+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>b3579740-32b9-4b79-85ae-be71839c5d11, 276d2c5e-a96f-48e6-8158-a18a68e3bd59, 5bf788b1-fa77-4fdb-a837-409af9c19e2d, 4b529632-8f30-4ae6-a588-8bca3971f20f, 659821ab-d0ad-40c2-984f-5052757c0782, 8dcf0175-07a3-4df3-8289-7b950a1de32b</td></tr><tr><th>steps</th> <td>forecast-challenger02-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'forecast-workshop-pipeline', 'create_time': datetime.datetime(2023, 7, 26, 19, 38, 56, 59951, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'forecast-control-model', 'version': 'f6165bb1-18c0-4bcb-a6c1-4aed8db53107', 'sha': '525ea2be4402725878382631c2c32b2e3f105bf78eedf41f3ac6d71c0dfa986b'}, {'name': 'forecast-challenger01-model', 'version': '21fe038c-fd2a-4ff7-90e6-6f85ea8dc6f1', 'sha': '41141f9accf5e4720e1dce7a74fce4dbc313f6fecb034bef90cec23fd850365c'}, {'name': 'forecast-challenger02-model', 'version': '1e506ed6-a478-4c0d-8b74-ccddac0075d9', 'sha': 'c740dbb02a650178065a7dd3d82b88b51d95dcc3fb90a02082389465f4a1a35e'}]}}, {'AuditResults': {'from': 1, 'to': None}}, {'MultiOut': {}}]\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.replace_with_shadow_deploy(0, control_model, [challenger_model_01, challenger_model_02])\n",
    "pipeline.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'forecast': [1764, 1749, 1743, 1741, 1740, 1740, 1740]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inferencedata = json.load(open(\"./data/testdata_dict.json\"))\n",
    "\n",
    "results = pipeline.infer(inferencedata)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "results = pipeline.infer(inferencedata)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this by looking at the pipeline logs and using the `metadata` filter to retrieve the logs.\n",
    "\n",
    "The original output is listed by `out.{variable_name}`, with the shadow outputs as `out_{model.variable_name}`.  For this example, this is `out.json`, `out_forecast-challenger01-model.json`, etc.  The command below will filter for only the time and the output variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pipeline log schema has changed over the logs requested 2 newest records retrieved successfully, newest record seen was at <datetime>. Please request additional records separately\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out.json</th>\n",
       "      <th>out_forecast-challenger01-model.json</th>\n",
       "      <th>out_forecast-challenger02-model.json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-26 20:59:34.001</td>\n",
       "      <td>{\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}</td>\n",
       "      <td>{\"forecast\":[1703,1757,1737,1744,1742,1743,1742]}</td>\n",
       "      <td>{\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-26 20:59:28.528</td>\n",
       "      <td>{\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}</td>\n",
       "      <td>{\"forecast\":[1703,1757,1737,1744,1742,1743,1742]}</td>\n",
       "      <td>{\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time                                           out.json  \\\n",
       "0 2023-07-26 20:59:34.001  {\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}   \n",
       "1 2023-07-26 20:59:28.528  {\"forecast\":[1764,1749,1743,1741,1740,1740,1740]}   \n",
       "\n",
       "                out_forecast-challenger01-model.json  \\\n",
       "0  {\"forecast\":[1703,1757,1737,1744,1742,1743,1742]}   \n",
       "1  {\"forecast\":[1703,1757,1737,1744,1742,1743,1742]}   \n",
       "\n",
       "                out_forecast-challenger02-model.json  \n",
       "0  {\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}  \n",
       "1  {\"forecast\":[1814,1814,1814,1814,1814,1814,1814]}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logs = pipeline.logs()\n",
    "display(logs.filter(regex = 'time|out.*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "Undeploy the pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>forecast-workshop-pipeline</td></tr><tr><th>created</th> <td>2023-07-26 19:38:56.059951+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-26 20:59:22.730271+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>b3579740-32b9-4b79-85ae-be71839c5d11, 276d2c5e-a96f-48e6-8158-a18a68e3bd59, 5bf788b1-fa77-4fdb-a837-409af9c19e2d, 4b529632-8f30-4ae6-a588-8bca3971f20f, 659821ab-d0ad-40c2-984f-5052757c0782, 8dcf0175-07a3-4df3-8289-7b950a1de32b</td></tr><tr><th>steps</th> <td>forecast-challenger02-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'forecast-workshop-pipeline', 'create_time': datetime.datetime(2023, 7, 26, 19, 38, 56, 59951, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'forecast-control-model', 'version': 'f6165bb1-18c0-4bcb-a6c1-4aed8db53107', 'sha': '525ea2be4402725878382631c2c32b2e3f105bf78eedf41f3ac6d71c0dfa986b'}, {'name': 'forecast-challenger01-model', 'version': '21fe038c-fd2a-4ff7-90e6-6f85ea8dc6f1', 'sha': '41141f9accf5e4720e1dce7a74fce4dbc313f6fecb034bef90cec23fd850365c'}, {'name': 'forecast-challenger02-model', 'version': '1e506ed6-a478-4c0d-8b74-ccddac0075d9', 'sha': 'c740dbb02a650178065a7dd3d82b88b51d95dcc3fb90a02082389465f4a1a35e'}]}}, {'AuditResults': {'from': 1, 'to': None}}, {'MultiOut': {}}]\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
